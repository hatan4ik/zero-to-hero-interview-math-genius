{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Zero\u2192Hero Interview \u2014 Math\u2011Genius Edition","text":"<p>A complete, opinionated prep repository for senior/principal coding + system design interviews. Built around three pillars: 1. Coding Interview (7+ archetypes) \u2014 math \u2192 pseudocode \u2192 Python/Java/C++ \u2192 traces. 2. System Design (Zero\u2192Hero) \u2014 equations, modeling, cloud mappings, patterns-as-theorems. 3. Execution Plan \u2014 8-week daily schedule, rubrics, mistake logs.</p> <p>Everything is plain text + code. Clone and go.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Structure</li> <li>What's inside (quick links)</li> <li>Quickstart</li> <li>CI &amp; Docs</li> <li>Run code / tests locally</li> <li>Authoring notes</li> <li>If you came for one thing</li> <li>Notes</li> </ul>"},{"location":"#structure","title":"Structure","text":"<ul> <li>part1-coding</li> <li>01-hash-two-sum</li> <li>02-sliding-window-longest-substring</li> <li>03-bfs-level-order</li> <li>04-intervals-merge</li> <li>05-dp-climbing-stairs</li> <li>06-toposort-course-schedule</li> <li>07-heap-meeting-rooms</li> <li>08-advanced-patterns</li> <li>10-segment-tree-range-query</li> <li>part2-system-design</li> <li>01-foundations</li> <li>02-caching-lb-queues</li> <li>03-sharding-replication-quorums</li> <li>04-observability-reliability-security</li> <li>05-cloud-mapping</li> <li>06-case-studies</li> <li>07-failure-engineering</li> <li>08-modern-patterns</li> <li>09-war-stories</li> <li>10-faang-deep-dives</li> <li>11-ml-systems</li> <li>part3-execution</li> <li>01-8-week-schedule.md</li> <li>02-mock-rubrics.md</li> <li>03-mistake-log-template.md</li> <li>04-cheatsheets.md</li> <li>05-practice-set.md</li> <li>06-faang-specific-prep.md</li> </ul>"},{"location":"#whats-inside-quick-links","title":"What's inside (quick links)","text":"<ul> <li>Part 1 \u2014 Coding archetypes with Python/Java/C++: Two Sum, Sliding Window, BFS, Intervals, DP, Topo, Heap/Greedy, Advanced Patterns, Segment Tree.</li> <li>Part 2 \u2014 System design: Foundations, Caching/LB/Queues, Sharding/Replication, Observability, Cloud Mapping, Case Studies, Failure Engineering, Modern Patterns, War Stories.</li> <li>Part 3 \u2014 Execution: 8-Week Schedule, Rubrics, Mistake Log, Cheatsheets, Practice Set, FAANG-specific Prep.</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<pre><code>git init\ngit add .\ngit commit -m \"Zero\u2192Hero Interview (Math-Genius Edition)\"\n# create an empty repo on GitHub, then:\ngit remote add origin &lt;YOUR_GITHUB_REMOTE_URL&gt;\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"#ci-docs","title":"CI &amp; Docs","text":"<ul> <li>GitHub Actions: <code>.github/workflows/ci.yml</code> runs Python tests (pytest), compiles Java and C++, and runs sanity checks.</li> <li>Docs site: MkDocs config in <code>mkdocs.yml</code> with content under <code>docs/</code>. Build locally with:   <pre><code>pip install mkdocs mkdocs-material\nmkdocs serve  # http://127.0.0.1:8000\n</code></pre></li> </ul>"},{"location":"#run-code-tests-locally","title":"Run code / tests locally","text":"<ul> <li>Python: <code>pip install -r requirements-dev.txt &amp;&amp; pytest</code></li> <li>C++: <code>g++ -std=c++17 part1-coding/&lt;chapter&gt;/cpp/*.cpp &amp;&amp; ./a.out</code> (or your preferred build)</li> <li>Java: <code>javac part1-coding/&lt;chapter&gt;/java/*.java &amp;&amp; java MainClass</code> (or <code>mvn test</code> if you add a POM)</li> </ul>"},{"location":"#authoring-notes","title":"Authoring notes","text":"<ul> <li>Docs mirror repo files via symlinks/snippets: edit under <code>part1-coding/</code>, <code>part2-system-design/</code>, <code>part3-execution/</code>, and MkDocs will pull them in.</li> <li>Voice: math first, then pseudocode, then code, with a short \u201chow I\u2019d say it in an interview\u201d narration.</li> <li>Keep equations and real numbers in system design; prefer concrete examples over generalities.</li> </ul>"},{"location":"#if-you-came-for-one-thing","title":"If you came for one thing","text":"<ul> <li>System design formulas and examples: start at part2-system-design/01-foundations/README.md.</li> <li>Coding archetypes: pick any Part 1 folder; each has math, pseudocode, and Python/Java/C++.</li> <li>Schedule/rubrics to drive practice: part3-execution.</li> </ul>"},{"location":"#notes","title":"Notes","text":"<ul> <li>Part 1 folders include math reasoning, pseudocode, traces, and Python/Java/C++ implementations for each archetype.</li> <li>Part 2 leans on equations, real numbers, and pattern tradeoffs; tools under <code>part2-system-design/tools/</code>.</li> <li>Part 3 provides schedules, rubrics, and practice scaffolding to make the prep repeatable.</li> </ul>"},{"location":"part1-coding/01-hash-two-sum/","title":"Hash / Lookup \u2014 Complement Existence Theorem","text":""},{"location":"part1-coding/01-hash-two-sum/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Complement Theorem: For array S={s_i} and target t, solution exists iff \u2203i,j: s_i + s_j = t \u27fa \u2203i: (t - s_i) \u2208 S.</p> <p>Hash Function Properties: Using hash map H: value \u2192 index with expected O(1) lookup time. For each element x, we check membership of complement (t-x) in constant time.</p> <p>Correctness Proof: If pair (i,j) exists with s_i + s_j = t, our algorithm will find it when processing the second element of the pair, since the first element's complement will already be stored in the hash map.</p> <p>Optimality: Single pass through array is necessary (must examine each element at least once). Hash lookup is optimal for membership testing.</p> <p>Complexity: Time O(n), Space O(n) for hash map storage.</p>"},{"location":"part1-coding/01-hash-two-sum/#visual-representation","title":"Visual Representation","text":"<pre><code>Array: [2, 7, 11, 15], Target: 9\n\nStep 1: Process element 2\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2  \u2502  7  \u2502 11  \u2502 15  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2191\n  i=0\n\nNeed: 9 - 2 = 7\nHashMap: {} (empty)\n7 not found \u2192 Store {2: 0}\n\nStep 2: Process element 7  \n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2  \u2502  7  \u2502 11  \u2502 15  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2191\n        i=1\n\nNeed: 9 - 7 = 2\nHashMap: {2: 0}\n2 found at index 0! \u2192 Return [0, 1]\n\n\ud83c\udfaf Solution: indices [0, 1] because nums[0] + nums[1] = 2 + 7 = 9\n</code></pre>"},{"location":"part1-coding/01-hash-two-sum/#hash-table-visualization","title":"Hash Table Visualization","text":"<pre><code>Iteration 0:          Iteration 1:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 HashMap     \u2502      \u2502 HashMap     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 (empty)     \u2502  \u2192   \u2502 2 \u2192 0       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502 7 \u2192 ? (found!)\u2502\n                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"part1-coding/01-hash-two-sum/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Loop Invariant: At iteration i, hash map contains all elements s[0...i-1] with their indices, and no valid pair exists among processed elements.</p>"},{"location":"part1-coding/01-hash-two-sum/#pseudocode","title":"Pseudocode","text":"<pre><code>function twoSum(nums, target):\n    seen = map()\n    for i in 0..n-1:\n        need = target - nums[i]\n        if seen contains need: return [seen[need], i]\n        seen[nums[i]] = i\n    return []\n</code></pre>"},{"location":"part1-coding/01-hash-two-sum/#trace","title":"Trace","text":"i x need seen action 0 2 7 {{}} store 2\u21920 1 7 2 {{2\u21920}} found \u2192 [0,1]"},{"location":"part1-coding/01-hash-two-sum/#narration","title":"Narration","text":"<p>\"Trade memory for speed; O(n) time, O(n) space. Same as cache lookup or log correlation.\"</p> \ud83d\udc0d Python Implementation <pre><code>from typing import List\n\ndef two_sum(nums: List[int], target: int) -&gt; List[int]:\n    seen = {}\n    for i, x in enumerate(nums):\n        if target - x in seen:\n            return [seen[target - x], i]\n        seen[x] = i\n    return []\n</code></pre> \u26a1 C++ Implementation <pre><code>vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target){\n    unordered_map&lt;int,int&gt; seen;\n    for(int i=0;i&lt;(int)nums.size();++i){\n        int need = target - nums[i];\n        if(seen.contains(need)) return {seen.at(need), i};\n        seen[nums[i]] = i;\n    }\n    return {};\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\npublic class TwoSum {\n    public static int[] twoSum(int[] a, int t){\n        Map&lt;Integer,Integer&gt; m = new HashMap&lt;&gt;();\n        for(int i=0;i&lt;a.length;i++){\n            int need = t - a[i];\n            if(m.containsKey(need)) return new int[]{m.get(need), i};\n            m.put(a[i], i);\n        }\n        return new int[0];\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>func twoSum(nums []int, target int) []int {\n    seen := make(map[int]int)\n    for i, x := range nums {\n        if j, ok := seen[target-x]; ok {\n            return []int{j, i}\n        }\n        seen[x] = i\n    }\n    return []int{}\n}\n</code></pre>"},{"location":"part1-coding/01-hash-two-sum/01-testing-with-curl/","title":"Tooling Guide: Testing with cURL","text":"<p><code>curl</code> is an essential tool for testing APIs and understanding system behavior. Here\u2019s how you can use it to test the idempotency and retry logic discussed in the case studies.</p>"},{"location":"part1-coding/01-hash-two-sum/01-testing-with-curl/#testing-idempotency","title":"Testing Idempotency","text":"<p>To test idempotency, you send the same request multiple times with the same <code>Idempotency-Key</code> header. The server should process the request only once.</p> <p>First Request: <pre><code># The server should process this and return a 200 OK.\ncurl -X POST https://api.example.com/payments \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Idempotency-Key: a1b2c3d4-e5f6-7890-1234-567890abcdef\" \\\n  -d '{\"amount\": 1000, \"currency\": \"usd\"}'\n</code></pre></p> <p>Second (Retry) Request: <pre><code># Send the exact same request again.\n# The server should recognize the key and return a cached 200 OK without reprocessing.\ncurl -X POST https://api.example.com/payments \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Idempotency-Key: a1b2c3d4-e5f6-7890-1234-567890abcdef\" \\\n  -d '{\"amount\": 1000, \"currency\": \"usd\"}'\n</code></pre></p> <p>A correct implementation will charge the customer only once. This is a simple but powerful way to verify the safety of your API.</p>"},{"location":"part1-coding/02-sliding-window-longest-substring/","title":"Sliding Window \u2014 Moving-Integral Invariant","text":""},{"location":"part1-coding/02-sliding-window-longest-substring/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Invariant Preservation: Maintain window W=[L,R) such that \u2200i,j \u2208 W: s[i] \u2260 s[j] (no duplicates).</p> <p>Amortized Analysis: Each character enters the window exactly once (when R advances) and exits at most once (when L advances). Since L is monotonically non-decreasing and bounded by R, total operations = O(n).</p> <p>Optimality Proof: For any position R, the maximum valid window ending at R is unique and determined by the rightmost occurrence of s[R] before position R. Our algorithm finds this optimally by maintaining the invariant.</p> <p>Complexity: Time O(n), Space O(min(m,n)) where m = alphabet size.</p>"},{"location":"part1-coding/02-sliding-window-longest-substring/#visual-representation","title":"Visual Representation","text":"<pre><code>String: \"abcabcbb\"\nStep-by-step sliding window expansion:\n\nStep 1: a|bcabcbb     Window=[0,1), Set={a}, Length=1\n        L R\n\nStep 2: ab|cabcbb     Window=[0,2), Set={a,b}, Length=2  \n        L  R\n\nStep 3: abc|abcbb     Window=[0,3), Set={a,b,c}, Length=3\n        L   R\n\nStep 4: abc|a|bcbb    Duplicate 'a' found! Shrink window\n        L   R         Remove 'a' from set, L moves right\n\nStep 5:  bc|a|bcbb    Window=[1,4), Set={b,c,a}, Length=3\n         L   R\n\nStep 6:  bca|b|cbb    Duplicate 'b' found! Shrink window  \n         L   R        Remove 'b','c' from set, L moves right\n\nStep 7:    a|b|cbb    Window=[3,5), Set={a,b}, Length=2\n           L R\n\nMaximum window length achieved: 3\n</code></pre>"},{"location":"part1-coding/02-sliding-window-longest-substring/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Loop Invariant: At iteration R, window [L,R) contains no duplicate characters, and L is the minimum index such that [L,R] would be valid.</p>"},{"location":"part1-coding/02-sliding-window-longest-substring/#pseudocode","title":"Pseudocode","text":"<pre><code>left=0; best=0; set=\u2205\nfor right in 0..n-1:\n    while s[right] in set:\n        remove s[left]; left++\n    add s[right]; best=max(best, right-left+1)\nreturn best\n</code></pre>"},{"location":"part1-coding/02-sliding-window-longest-substring/#trace-abba","title":"Trace (\"abba\")","text":"r ch L set_before action best 0 a 0 {{}} add a 1 1 b 0 {{a}} add b 2 2 b 0 {{a,b}} remove a,b; add b 2 3 a 2 {{b}} add a 2 \ud83d\udc0d Python Implementation <pre><code>def longest_unique(s: str) -&gt; int:\n    seen, L, best = set(), 0, 0\n    for R, ch in enumerate(s):\n        while ch in seen:\n            seen.remove(s[L]); L += 1\n        seen.add(ch)\n        best = max(best, R - L + 1)\n    return best\n</code></pre> \u26a1 C++ Implementation <pre><code>int lengthOfLongestSubstring(string s){\n    unordered_set&lt;char&gt; st; int l=0,b=0;\n    for(int r=0;r&lt;(int)s.size();++r){\n        while(st.count(s[r])) st.erase(s[l++]);\n        st.insert(s[r]); b=max(b, r-l+1);\n    }\n    return b;\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\npublic class LongestSubstring {\n    public static int lengthOfLongestSubstring(String s){\n        Set&lt;Character&gt; set = new HashSet&lt;&gt;();\n        int l=0,b=0;\n        for(int r=0;r&lt;s.length();r++){\n            while(set.contains(s.charAt(r))) set.remove(s.charAt(l++));\n            set.add(s.charAt(r));\n            b = Math.max(b, r-l+1);\n        }\n        return b;\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>func lengthOfLongestSubstring(s string) int {\n    seen := make(map[byte]bool)\n    l, best := 0, 0\n    for r := 0; r &lt; len(s); r++ {\n        for seen[s[r]] {\n            delete(seen, s[l])\n            l++\n        }\n        seen[s[r]] = true\n        if r-l+1 &gt; best {\n            best = r - l + 1\n        }\n    }\n    return best\n}\n</code></pre>"},{"location":"part1-coding/03-bfs-level-order/","title":"Tree/Graph BFS \u2014 Wavefront Propagation","text":""},{"location":"part1-coding/03-bfs-level-order/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Level Function: Define level \u2113(v) = min{edges from root to v}. BFS computes \u2113 for all reachable vertices optimally.</p> <p>Wavefront Expansion: Process vertices in non-decreasing order of distance from source. Queue maintains FIFO ordering to ensure level \u2113 vertices are processed before level \u2113+1.</p> <p>Correctness Proof: When vertex v at level \u2113 is dequeued, all vertices at levels 0,1,...,\u2113-1 have been processed. Children of v are at level \u2113+1, maintaining the invariant.</p> <p>Optimality: Each vertex and edge examined exactly once. No algorithm can do better than O(V+E) for reachability.</p> <p>Tree Specialization: For binary trees, E = V-1, so complexity becomes O(V). Level-order traversal groups vertices by distance from root.</p> <p>Complexity: Time O(V+E), Space O(W) where W = maximum width of any level.</p>"},{"location":"part1-coding/03-bfs-level-order/#visual-representation","title":"Visual Representation","text":"<pre><code>Binary Tree:           Level-by-Level Processing:\n\n      3               Level 0: [3]\n     / \\              Queue: [3] \u2192 Process 3, add children\n    9   20             Result: [[3]]\n   / \\    \\\n  15  7   15          Level 1: [9, 20]  \n                      Queue: [9,20] \u2192 Process 9,20, add children\n                      Result: [[3], [9,20]]\n\n                      Level 2: [15, 7, 15]\n                      Queue: [15,7,15] \u2192 Process all, no children\n                      Result: [[3], [9,20], [15,7,15]]\n</code></pre>"},{"location":"part1-coding/03-bfs-level-order/#bfs-wavefront-expansion","title":"BFS Wavefront Expansion","text":"<pre><code>Step 1: Initialize     Step 2: Process Level 0    Step 3: Process Level 1\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Queue: [3]    \u2502    \u2502Queue: [9,20]\u2502    \u2502Queue:[15,7,15]\u2502\n\u2502Level: []    \u2502    \u2502Level: [3]   \u2502    \u2502Level: [9,20]  \u2502\n\u2502Result: []   \u2502    \u2502Result:[[3]] \u2502    \u2502Result:[[3],   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502        [9,20]]\u2502\n                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nFinal Result: [[3], [9,20], [15,7,15]]\n</code></pre>"},{"location":"part1-coding/03-bfs-level-order/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Queue Invariant: At any point, queue contains vertices from at most two consecutive levels \u2113 and \u2113+1.</p>"},{"location":"part1-coding/03-bfs-level-order/#pseudocode","title":"Pseudocode","text":"<pre><code>queue=[root]; res=[]\nwhile queue:\n    level=[]\n    repeat size(queue) times:\n        node=pop(); append node.val\n        push children if exist\n    append level to res\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>from collections import deque\n\nclass Node:\n    def __init__(self, val, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\ndef level_order(root):\n    if not root: return []\n    q,res=deque([root]),[]\n    while q:\n        lvl=[]\n        for _ in range(len(q)):\n            n=q.popleft(); lvl.append(n.val)\n            if n.left: q.append(n.left)\n            if n.right: q.append(n.right)\n        res.append(lvl)\n    return res\n</code></pre> \u26a1 C++ Implementation <pre><code>vector&lt;vector&lt;int&gt;&gt; levelOrder(Node* root){\n    vector&lt;vector&lt;int&gt;&gt; res; if(!root) return res;\n    queue&lt;Node*&gt; q; q.push(root);\n    while(!q.empty()){\n        int sz=q.size(); vector&lt;int&gt; lvl;\n        for(int i=0;i&lt;sz;++i){\n            Node* n=q.front(); q.pop(); lvl.push_back(n-&gt;val);\n            if(n-&gt;left) q.push(n-&gt;left);\n            if(n-&gt;right) q.push(n-&gt;right);\n        } res.push_back(lvl);\n    } return res;\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\nclass TreeNode { int val; TreeNode left,right; TreeNode(int v){val=v;} }\npublic class LevelOrder {\n    public static List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root){\n        List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;&gt;();\n        if(root==null) return res;\n        Queue&lt;TreeNode&gt; q=new LinkedList&lt;&gt;(); q.add(root);\n        while(!q.isEmpty()){\n            int size=q.size(); List&lt;Integer&gt; lvl=new ArrayList&lt;&gt;();\n            for(int i=0;i&lt;size;i++){\n                TreeNode n=q.poll(); lvl.add(n.val);\n                if(n.left!=null) q.add(n.left);\n                if(n.right!=null) q.add(n.right);\n            } res.add(lvl);\n        } return res;\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>type TreeNode struct {\n    Val   int\n    Left  *TreeNode\n    Right *TreeNode\n}\n\nfunc levelOrder(root *TreeNode) [][]int {\n    if root == nil {\n        return [][]int{}\n    }\n    var result [][]int\n    queue := []*TreeNode{root}\n\n    for len(queue) &gt; 0 {\n        size := len(queue)\n        var level []int\n\n        for i := 0; i &lt; size; i++ {\n            node := queue[0]\n            queue = queue[1:]\n            level = append(level, node.Val)\n\n            if node.Left != nil {\n                queue = append(queue, node.Left)\n            }\n            if node.Right != nil {\n                queue = append(queue, node.Right)\n            }\n        }\n        result = append(result, level)\n    }\n    return result\n}\n</code></pre>"},{"location":"part1-coding/04-intervals-merge/","title":"Intervals / Sorting \u2014 Measure Union","text":""},{"location":"part1-coding/04-intervals-merge/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Measure Theory: Given intervals I\u2081,I\u2082,...,I\u2099 on \u211d, compute their union \u22c3I\u1d62 as disjoint intervals preserving total measure.</p> <p>Sorting Lemma: After sorting by start time, overlapping intervals appear consecutively. If intervals [a,b] and [c,d] overlap, then either a \u2264 c \u2264 b or c \u2264 a \u2264 d.</p> <p>Greedy Optimality: Process intervals left-to-right. For current interval [s,e], either it's disjoint from previous (start new interval) or overlapping (extend previous interval to max endpoint).</p> <p>Correctness Proof: Sorted order ensures we never miss an overlap. Greedy extension maximizes coverage at each step, producing minimal disjoint representation.</p> <p>Invariant: Result array contains disjoint intervals in sorted order, covering all processed input intervals.</p> <p>Complexity: Time O(n log n) for sorting + O(n) for merging = O(n log n), Space O(1) excluding output.</p>"},{"location":"part1-coding/04-intervals-merge/#visual-representation","title":"Visual Representation","text":"<pre><code>Input: [[1,3],[2,6],[8,10],[15,18]]\n\nStep 1: Sort by start time (already sorted)\n[1,3] [2,6] [8,10] [15,18]\n\nStep 2: Process intervals one by one\n\nInterval [1,3]:\n  1\u2500\u2500\u25003\nResult: [[1,3]]\n\nInterval [2,6]: Overlaps with [1,3] (2 \u2264 3)\n  1\u2500\u2500\u25003\n    2\u2500\u2500\u2500\u2500\u25006\n  1\u2500\u2500\u2500\u2500\u2500\u2500\u25006  (merged)\nResult: [[1,6]]\n\nInterval [8,10]: No overlap with [1,6] (8 &gt; 6)\n  1\u2500\u2500\u2500\u2500\u2500\u2500\u25006     8\u2500\u250010\nResult: [[1,6], [8,10]]\n\nInterval [15,18]: No overlap with [8,10] (15 &gt; 10)\n  1\u2500\u2500\u2500\u2500\u2500\u2500\u25006     8\u2500\u250010     15\u2500\u2500\u250018\nResult: [[1,6], [8,10], [15,18]]\n</code></pre>"},{"location":"part1-coding/04-intervals-merge/#merge-process-visualization","title":"Merge Process Visualization","text":"<pre><code>Before:  [1,3] [2,6] [8,10] [15,18]\n         \u251c\u2500\u2524   \u251c\u2500\u2500\u2524   \u251c\u2500\u2524    \u251c\u2500\u2500\u2524\n         \u2502 \u2502   \u2502  \u2502   \u2502 \u2502    \u2502  \u2502\n         1 3   2  6   8 10   15 18\n\nAfter:   [1,6]       [8,10] [15,18]\n         \u251c\u2500\u2500\u2500\u2500\u2524       \u251c\u2500\u2524    \u251c\u2500\u2500\u2524\n         \u2502    \u2502       \u2502 \u2502    \u2502  \u2502\n         1    6       8 10   15 18\n\nOverlap Detection:\n- [1,3] and [2,6]: 2 \u2264 3 \u2713 (overlap)\n- [1,6] and [8,10]: 8 &gt; 6 \u2717 (no overlap)\n- [8,10] and [15,18]: 15 &gt; 10 \u2717 (no overlap)\n</code></pre>"},{"location":"part1-coding/04-intervals-merge/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Merge Invariant: At step i, result contains optimal disjoint union of intervals [0...i-1], and result[-1].end \u2265 max(endpoints of merged intervals).</p>"},{"location":"part1-coding/04-intervals-merge/#pseudocode","title":"Pseudocode","text":"<pre><code>sort by start\nfor (s,e):\n  if res empty or res[-1].end &lt; s: push [s,e]\n  else res[-1].end = max(res[-1].end, e)\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>def merge(intervals):\n    intervals.sort(key=lambda x: x[0])\n    res=[]\n    for s,e in intervals:\n        if not res or res[-1][1] &lt; s: res.append([s,e])\n        else: res[-1][1] = max(res[-1][1], e)\n    return res\n</code></pre> \u26a1 C++ Implementation <pre><code>vector&lt;vector&lt;int&gt;&gt; merge(vector&lt;vector&lt;int&gt;&gt;&amp; in){\n    sort(in.begin(), in.end(), [](auto&amp;a, auto&amp;b){ return a[0] &lt; b[0]; });\n    vector&lt;vector&lt;int&gt;&gt; res;\n    for(auto &amp;c: in){\n        if(res.empty() || res.back()[1] &lt; c[0]) res.push_back(c);\n        else res.back()[1] = max(res.back()[1], c[1]);\n    } return res;\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\npublic class MergeIntervals {\n    public static int[][] merge(int[][] in){\n        Arrays.sort(in, Comparator.comparingInt(a -&gt; a[0]));\n        List&lt;int[]&gt; res=new ArrayList&lt;&gt;();\n        for(int[] cur: in){\n            if(res.isEmpty() || res.get(res.size()-1)[1] &lt; cur[0]) res.add(new int[]{cur[0],cur[1]});\n            else res.get(res.size()-1)[1] = Math.max(res.get(res.size()-1)[1], cur[1]);\n        }\n        return res.toArray(new int[res.size()][]);\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>import \"sort\"\n\nfunc merge(intervals [][]int) [][]int {\n    if len(intervals) == 0 {\n        return [][]int{}\n    }\n\n    sort.Slice(intervals, func(i, j int) bool {\n        return intervals[i][0] &lt; intervals[j][0]\n    })\n\n    var result [][]int\n    for _, curr := range intervals {\n        if len(result) == 0 || result[len(result)-1][1] &lt; curr[0] {\n            result = append(result, curr)\n        } else {\n            if curr[1] &gt; result[len(result)-1][1] {\n                result[len(result)-1][1] = curr[1]\n            }\n        }\n    }\n    return result\n}\n</code></pre>"},{"location":"part1-coding/05-dp-climbing-stairs/","title":"Dynamic Programming \u2014 Linear Recurrence","text":""},{"location":"part1-coding/05-dp-climbing-stairs/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Recurrence Relation: f(n) = f(n-1) + f(n-2) with base cases f(1)=1, f(2)=2. This is the Fibonacci sequence shifted by one index.</p> <p>Principle of Optimality: To reach step n, we must come from either step n-1 (taking 1 step) or step n-2 (taking 2 steps). The number of ways is the sum of ways to reach these predecessor states.</p> <p>Mathematical Induction:  - Base: f(1)=1, f(2)=2 \u2713 - Hypothesis: f(k) is correct for all k &lt; n - Step: f(n) = f(n-1) + f(n-2) by definition of the problem</p> <p>Closed Form Solution: f(n) = (\u03c6\u207f\u207a\u00b9 - \u03c8\u207f\u207a\u00b9)/\u221a5 where \u03c6 = (1+\u221a5)/2 (golden ratio), \u03c8 = (1-\u221a5)/2.</p> <p>Space Optimization: Since f(n) only depends on previous two values, we can use O(1) space with rolling variables instead of O(n) array.</p> <p>Complexity: Time O(n), Space O(1) with rolling technique.</p>"},{"location":"part1-coding/05-dp-climbing-stairs/#visual-representation","title":"Visual Representation","text":"<pre><code>Climbing Stairs (n=5): How many ways to reach step 5?\n\nStaircase Visualization:\n     \u250c\u2500\u2500\u2500\u2510 5\n   \u250c\u2500\u2524   \u2502\n \u250c\u2500\u2524 \u2502   \u2502\n\u250c\u2524 \u2502 \u2502   \u2502\n\u2502\u2502 \u2502 \u2502   \u2502\n\u2502\u2502 \u2502 \u2502   \u2502\n\u2502\u2502 \u2502 \u2502   \u2502\n\u25001 2 3 4   5\n\nRecurrence Relation: f(n) = f(n-1) + f(n-2)\n\nStep-by-step calculation:\nf(1) = 1  (base case: 1 way to reach step 1)\nf(2) = 2  (base case: 2 ways to reach step 2)\nf(3) = f(2) + f(1) = 2 + 1 = 3\nf(4) = f(3) + f(2) = 3 + 2 = 5  \nf(5) = f(4) + f(3) = 5 + 3 = 8\n</code></pre>"},{"location":"part1-coding/05-dp-climbing-stairs/#fibonacci-pattern-visualization","title":"Fibonacci Pattern Visualization","text":"<pre><code>Step:  1  2  3  4  5  6  7  8 ...\nWays:  1  2  3  5  8 13 21 34 ...\n       \u2502  \u2502  \u2502  \u2502  \u2502  \u2502  \u2502  \u2502\n       \u2514\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500 Fibonacci sequence!\n          3  5  8 13 21 34 55\n\nRolling Variables (Space Optimization):\nIteration 3: a=1, b=2 \u2192 c=1+2=3, a=2, b=3\nIteration 4: a=2, b=3 \u2192 c=2+3=5, a=3, b=5\nIteration 5: a=3, b=5 \u2192 c=3+5=8, a=5, b=8\n\nResult: f(5) = 8 ways\n</code></pre>"},{"location":"part1-coding/05-dp-climbing-stairs/#ways-to-reach-each-step","title":"Ways to Reach Each Step","text":"<pre><code>Step 1: \u2022 (1 way)\n        1-step\n\nStep 2: \u2022\u2022 (2 ways)\n        1-step + 1-step\n        2-step\n\nStep 3: \u2022\u2022\u2022 (3 ways)\n        1+1+1\n        1+2\n        2+1\n\nStep 4: \u2022\u2022\u2022\u2022 (5 ways)\n        1+1+1+1\n        1+1+2\n        1+2+1  \n        2+1+1\n        2+2\n</code></pre>"},{"location":"part1-coding/05-dp-climbing-stairs/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Loop Invariant: At iteration i, variables a and b contain f(i-1) and f(i) respectively.</p>"},{"location":"part1-coding/05-dp-climbing-stairs/#pseudocode","title":"Pseudocode","text":"<pre><code>if n&lt;=2: return n\na=1; b=2\nfor i in 3..n: c=a+b; a=b; b=c\nreturn b\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>def climb_stairs(n:int)-&gt;int:\n    if n&lt;=2: return n\n    a,b=1,2\n    for _ in range(3, n+1):\n        a, b = b, a + b\n    return b\n</code></pre> \u26a1 C++ Implementation <pre><code>int climbStairs(int n){\n    if(n&lt;=2) return n; int a=1,b=2;\n    for(int i=3;i&lt;=n;i++){ int c=a+b; a=b; b=c; } return b;\n}\n</code></pre> \u2615 Java Implementation <pre><code>public class ClimbStairs {\n    public static int climbStairs(int n){\n        if(n&lt;=2) return n;\n        int a=1,b=2;\n        for(int i=3;i&lt;=n;i++){ int c=a+b; a=b; b=c; }\n        return b;\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>func climbStairs(n int) int {\n    if n &lt;= 2 {\n        return n\n    }\n    a, b := 1, 2\n    for i := 3; i &lt;= n; i++ {\n        a, b = b, a+b\n    }\n    return b\n}\n</code></pre>"},{"location":"part1-coding/06-toposort-course-schedule/","title":"Topological Sort \u2014 Partial Order Linearization","text":""},{"location":"part1-coding/06-toposort-course-schedule/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Partial Order Theory: Given directed acyclic graph (DAG) G=(V,E), a topological ordering is a linear arrangement of vertices such that for every edge (u,v), u appears before v.</p> <p>Existence Theorem: A directed graph has a topological ordering if and only if it is acyclic (DAG). This follows from the fact that cycles create circular dependencies.</p> <p>Kahn's Algorithm Correctness:  1. Invariant: Vertices with indegree 0 have no unprocessed predecessors 2. Progress: Removing a vertex decreases indegree of successors 3. Termination: Either all vertices processed (valid topological order) or cycle detected</p> <p>Cycle Detection: If |output| &lt; |V|, then remaining vertices form strongly connected components (cycles).</p> <p>Uniqueness: Topological ordering is unique iff the graph is a Hamiltonian path. Otherwise, multiple valid orderings exist.</p> <p>Complexity: Time O(V+E) for building graph + processing each vertex/edge once, Space O(V+E) for adjacency list.</p>"},{"location":"part1-coding/06-toposort-course-schedule/#visual-representation","title":"Visual Representation","text":"<pre><code>Course Prerequisites: [[1,0], [2,0], [3,1], [3,2]]\nMeaning: Course 1 requires Course 0, Course 2 requires Course 0, etc.\n\nDependency Graph:\n    0 \u2500\u2500\u2500\u252c\u2500\u2500\u2500 1 \u2500\u2500\u2500 3\n        \u2502       \u2502   \u2571\n        \u2502       \u2502  \u2571\n        \u2514\u2500\u2500\u2500 2 \u2500\u2500\u2518\n\nIndegree Count:\nNode 0: indegree = 0 (no prerequisites)\nNode 1: indegree = 1 (requires course 0)\nNode 2: indegree = 1 (requires course 0)  \nNode 3: indegree = 2 (requires courses 1 and 2)\n</code></pre>"},{"location":"part1-coding/06-toposort-course-schedule/#kahns-algorithm-step-by-step","title":"Kahn's Algorithm Step-by-Step","text":"<pre><code>Step 1: Initialize\nQueue: [0]  (nodes with indegree 0)\nIndegree: [0, 1, 1, 2]\nResult: []\n\nStep 2: Process node 0\nQueue: [1, 2]  (after reducing indegrees of 1,2)\nIndegree: [0, 0, 0, 2]\nResult: [0]\n\nStep 3: Process node 1\nQueue: [2]  (after reducing indegree of 3)\nIndegree: [0, 0, 0, 1]\nResult: [0, 1]\n\nStep 4: Process node 2  \nQueue: [3]  (after reducing indegree of 3)\nIndegree: [0, 0, 0, 0]\nResult: [0, 1, 2]\n\nStep 5: Process node 3\nQueue: []  (no more nodes)\nIndegree: [0, 0, 0, 0]\nResult: [0, 1, 2, 3]\n\nValid topological order: 0 \u2192 1 \u2192 2 \u2192 3\n</code></pre>"},{"location":"part1-coding/06-toposort-course-schedule/#cycle-detection-visualization","title":"Cycle Detection Visualization","text":"<pre><code>No Cycle (DAG):           With Cycle:\n    A \u2500\u2500\u2500 B                A \u2500\u2500\u2500 B\n    \u2502   \u2502                \u2502   \u2502\n    \u2502   \u2502                \u2502   \u2502\n    C \u2500\u2500\u2500 D                C \u2500\u2500\u2500 D\n                              \u2502   \u2502\n                              \u2514\u2500\u2500\u2500\u2518\n\nResult: All nodes         Result: Some nodes\n        processed                 remain unprocessed\n        (valid topo sort)         (cycle detected)\n</code></pre>"},{"location":"part1-coding/06-toposort-course-schedule/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Queue Invariant: At any point, queue contains exactly the vertices with current indegree 0 (no unprocessed dependencies).</p>"},{"location":"part1-coding/06-toposort-course-schedule/#pseudocode","title":"Pseudocode","text":"<pre><code>build graph + indegree\nqueue = nodes with indeg 0\nwhile queue:\n  u=pop; append u\n  for v in adj[u]: indeg[v]--; if indeg[v]==0 push v\nif len(order)==n ok else cycle\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>from collections import defaultdict, deque\nfrom typing import List, Optional\n\ndef topo_sort(n: int, edges: List[List[int]]) -&gt; Optional[List[int]]:\n    g=defaultdict(list); indeg=[0 for _ in range(n)]\n    for a,b in edges: g[b].append(a); indeg[a]+=1\n    q=deque([i for i in range(n) if indeg[i]==0]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in g[u]:\n            indeg[v]-=1\n            if indeg[v]==0: q.append(v)\n    return order if len(order) == n else None\n</code></pre> \u26a1 C++ Implementation <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\nvector&lt;int&gt; topoSort(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges){\n    vector&lt;vector&lt;int&gt;&gt; g(n); vector&lt;int&gt; indeg(n);\n    for(auto &amp;e: edges){ g[e[1]].push_back(e[0]); indeg[e[0]]++; }\n    queue&lt;int&gt; q; \n    for(int i=0;i&lt;n;i++) if(indeg[i]==0) q.push(i);\n    vector&lt;int&gt; ord;\n    while(!q.empty()){\n        int u=q.front(); q.pop(); ord.push_back(u);\n        for(int v: g[u]) if(--indeg[v]==0) q.push(v);\n    }\n    return (int)ord.size()==n?ord:vector&lt;int&gt;{};\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\nimport java.util.stream.IntStream;\n\npublic class TopoSort {\n    public static int[] topoSort(int n, int[][] edges){\n        List&lt;List&lt;Integer&gt;&gt; g=new ArrayList&lt;&gt;();\n        for(int i=0;i&lt;n;i++) g.add(new ArrayList&lt;&gt;());\n        int[] indeg=new int[n];\n        for(int[] e: edges){ g.get(e[1]).add(e[0]); indeg[e[0]]++; }\n        Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();\n        IntStream.range(0, n).filter(i -&gt; indeg[i] == 0).forEach(q::add);\n        int[] order=new int[n]; int k=0;\n        while(!q.isEmpty()){\n            int u=q.poll(); order[k++]=u;\n            for(int v: g.get(u)) if(--indeg[v]==0) q.add(v);\n        }\n        return k==n?order:new int[0];\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>func topoSort(n int, edges [][]int) []int {\n    graph := make([][]int, n)\n    indegree := make([]int, n)\n\n    for _, edge := range edges {\n        graph[edge[1]] = append(graph[edge[1]], edge[0])\n        indegree[edge[0]]++\n    }\n\n    var queue []int\n    for i := 0; i &lt; n; i++ {\n        if indegree[i] == 0 {\n            queue = append(queue, i)\n        }\n    }\n\n    var result []int\n    for len(queue) &gt; 0 {\n        u := queue[0]\n        queue = queue[1:]\n        result = append(result, u)\n\n        for _, v := range graph[u] {\n            indegree[v]--\n            if indegree[v] == 0 {\n                queue = append(queue, v)\n            }\n        }\n    }\n\n    if len(result) == n {\n        return result\n    }\n    return []int{}\n}\n</code></pre>"},{"location":"part1-coding/07-heap-meeting-rooms/","title":"Greedy / Heap \u2014 Meeting Rooms II","text":""},{"location":"part1-coding/07-heap-meeting-rooms/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Interval Scheduling Theory: Given n intervals [s\u1d62, e\u1d62], find minimum number of resources (rooms) needed such that no two overlapping intervals use the same resource.</p> <p>Greedy Optimality: Process intervals by start time. For each new interval, reuse the earliest-finishing room if possible, otherwise allocate new room. This greedy choice is optimal.</p> <p>Proof of Correctness:  1. Lower Bound: At any time t, if k intervals are active, we need \u2265 k rooms 2. Upper Bound: Our algorithm never uses more rooms than the maximum overlap at any point 3. Optimality: Algorithm achieves the lower bound, hence optimal</p> <p>Heap Invariant: Min-heap contains end times of currently active meetings. Heap size = current room count.</p> <p>Critical Insight: We only care about the earliest ending meeting for room reuse, not which specific room. This reduces the problem to tracking minimum end times.</p> <p>Complexity: Time O(n log n) for sorting + n heap operations, Space O(n) for heap storage.</p>"},{"location":"part1-coding/07-heap-meeting-rooms/#visual-representation","title":"Visual Representation","text":"<pre><code>Meetings: [[0,30], [5,10], [15,20]]\n\nTimeline Visualization:\n0    5    10   15   20   25   30\n|\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500| Room 1: [0,30]\n     |\u2500\u2500\u2500\u2500\u2500|                           Room 2: [5,10]\n               |\u2500\u2500\u2500\u2500\u2500|                 Room 3: [15,20]\n\nMaximum overlap: 2 rooms needed (during [5,10] when Room 1 and Room 2 overlap)\n</code></pre>"},{"location":"part1-coding/07-heap-meeting-rooms/#min-heap-algorithm-visualization","title":"Min-Heap Algorithm Visualization","text":"<pre><code>Step 1: Sort by start time\nMeetings: [[0,30], [5,10], [15,20]]\n\nStep 2: Process [0,30]\nHeap: [30]  (end time of meeting in room 1)\nRooms needed: 1\n\nStep 3: Process [5,10]\nCan reuse room? 30 &gt; 5 (No, room 1 still occupied)\nHeap: [10, 30]  (add new room)\nRooms needed: 2\n\nStep 4: Process [15,20]\nCan reuse room? min(10,30) = 10 \u2264 15 (Yes, room 2 is free)\nHeap: [20, 30]  (reuse room 2, update end time)\nRooms needed: 2\n\nFinal answer: 2 rooms\n</code></pre>"},{"location":"part1-coding/07-heap-meeting-rooms/#heap-state-transitions","title":"Heap State Transitions","text":"<pre><code>Initial:     After [0,30]:   After [5,10]:   After [15,20]:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Heap  \u2502    \u2502 Heap  \u2502     \u2502 Heap  \u2502     \u2502 Heap  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 []    \u2502    \u2502 [30]  \u2502     \u2502[10,30]\u2502     \u2502[20,30]\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nSize: 0      Size: 1       Size: 2       Size: 2\n</code></pre>"},{"location":"part1-coding/07-heap-meeting-rooms/#room-reuse-logic","title":"Room Reuse Logic","text":"<pre><code>For each new meeting [start, end]:\n\n1. Check if earliest ending room is free:\n   if heap.min \u2264 start:\n       \u2713 Reuse room (pop old end time)\n   else:\n       \u2717 Need new room\n\n2. Add current meeting's end time to heap\n\n3. Heap size = current rooms needed\n</code></pre>"},{"location":"part1-coding/07-heap-meeting-rooms/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Room Invariant: At processing interval i, heap contains end times of meetings that haven't finished yet, representing occupied rooms.</p>"},{"location":"part1-coding/07-heap-meeting-rooms/#pseudocode","title":"Pseudocode","text":"<pre><code>sort intervals by start\nheap=[]\nfor (s,e):\n  if heap and heap.min &lt;= s: pop\n  push e\nreturn size(heap)\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>import heapq\n\ndef min_meeting_rooms(intervals):\n    intervals.sort(key=lambda x: x[0])\n    h=[]\n    for s,e in intervals:\n        if h and h[0] &lt;= s: heapq.heappop(h)\n        heapq.heappush(h,e)\n    return len(h)\n</code></pre> \u26a1 C++ Implementation <pre><code>int minMeetingRooms(vector&lt;vector&lt;int&gt;&gt;&amp; in){\n    sort(in.begin(), in.end(), [](auto&amp;a, auto&amp;b){ return a[0] &lt; b[0]; });\n    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq;\n    for(auto &amp;m: in){\n        if(!pq.empty() &amp;&amp; pq.top() &lt;= m[0]) pq.pop();\n        pq.push(m[1]);\n    }\n    return (int)pq.size();\n}\n</code></pre> \u2615 Java Implementation <pre><code>import java.util.*;\npublic class MeetingRoomsII {\n    public static int minMeetingRooms(int[][] in){\n        Arrays.sort(in,(a,b)-&gt;a[0]-b[0]);\n        PriorityQueue&lt;Integer&gt; pq=new PriorityQueue&lt;&gt;();\n        for(int[] m: in){\n            if(!pq.isEmpty() &amp;&amp; pq.peek()&lt;=m[0]) pq.poll();\n            pq.add(m[1]);\n        }\n        return pq.size();\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>import (\n    \"container/heap\"\n    \"sort\"\n)\n\ntype IntHeap []int\n\nfunc (h IntHeap) Len() int           { return len(h) }\nfunc (h IntHeap) Less(i, j int) bool { return h[i] &lt; h[j] }\nfunc (h IntHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\nfunc (h *IntHeap) Push(x interface{}) {\n    *h = append(*h, x.(int))\n}\nfunc (h *IntHeap) Pop() interface{} {\n    old := *h\n    n := len(old)\n    x := old[n-1]\n    *h = old[0 : n-1]\n    return x\n}\n\nfunc minMeetingRooms(intervals [][]int) int {\n    if len(intervals) == 0 {\n        return 0\n    }\n\n    sort.Slice(intervals, func(i, j int) bool {\n        return intervals[i][0] &lt; intervals[j][0]\n    })\n\n    h := &amp;IntHeap{}\n    heap.Init(h)\n\n    for _, interval := range intervals {\n        if h.Len() &gt; 0 &amp;&amp; (*h)[0] &lt;= interval[0] {\n            heap.Pop(h)\n        }\n        heap.Push(h, interval[1])\n    }\n\n    return h.Len()\n}\n</code></pre>"},{"location":"part1-coding/08-advanced-patterns/","title":"Advanced Patterns \u2014 FAANG L5/L6 Level","text":""},{"location":"part1-coding/08-advanced-patterns/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Advanced Data Structures Theory: These patterns represent sophisticated algorithmic techniques that achieve near-optimal complexity through mathematical insights and invariant preservation.</p> <p>Amortized Analysis: Many advanced structures use potential method or accounting method to achieve better average-case performance than worst-case bounds suggest.</p> <p>Information Theory: Structures like tries and segment trees organize information hierarchically to minimize query complexity through divide-and-conquer principles.</p>"},{"location":"part1-coding/08-advanced-patterns/#union-find-disjoint-set","title":"Union-Find (Disjoint Set)","text":""},{"location":"part1-coding/08-advanced-patterns/#mathematical-foundation","title":"Mathematical Foundation","text":"<p>Equivalence Relations: Maintains partition of set S into disjoint equivalence classes under relation ~. Operations: find(x) returns representative, union(x,y) merges classes.</p> <p>Path Compression: Flattens tree during find operations. Amortized analysis shows O(\u03b1(n)) per operation where \u03b1 is inverse Ackermann function (effectively constant for practical n).</p> <p>Union by Rank: Maintains tree balance by always attaching smaller tree to larger tree root, ensuring height \u2264 log n.</p> <p>Complexity Analysis: <pre><code>\u03b1(n) - Inverse Ackermann Function:\n\u03b1(1) = 1\n\u03b1(4) = 2  \n\u03b1(16) = 3\n\u03b1(65536) = 4\n\u03b1(2^65536) = 5\n\nFor all practical n: \u03b1(n) \u2264 5 (effectively constant)\n</code></pre> Complexity: Time O(\u03b1(n)) amortized per operation, Space O(n)</p> \ud83d\udc0d Python Implementation <pre><code>class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            self.parent[x] = self.find(self.parent[x])  # Path compression\n        return self.parent[x]\n\n    def union(self, x, y):\n        px, py = self.find(x), self.find(y)\n        if px == py: return False\n        if self.rank[px] &lt; self.rank[py]: px, py = py, px\n        self.parent[py] = px\n        if self.rank[px] == self.rank[py]: self.rank[px] += 1\n        return True\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>type UnionFind struct {\n    parent []int\n    rank   []int\n}\n\nfunc NewUnionFind(n int) *UnionFind {\n    parent := make([]int, n)\n    rank := make([]int, n)\n    for i := 0; i &lt; n; i++ {\n        parent[i] = i\n    }\n    return &amp;UnionFind{parent: parent, rank: rank}\n}\n\nfunc (uf *UnionFind) Find(x int) int {\n    if uf.parent[x] != x {\n        uf.parent[x] = uf.Find(uf.parent[x]) // Path compression\n    }\n    return uf.parent[x]\n}\n\nfunc (uf *UnionFind) Union(x, y int) bool {\n    px, py := uf.Find(x), uf.Find(y)\n    if px == py {\n        return false\n    }\n    if uf.rank[px] &lt; uf.rank[py] {\n        px, py = py, px\n    }\n    uf.parent[py] = px\n    if uf.rank[px] == uf.rank[py] {\n        uf.rank[px]++\n    }\n    return true\n}\n</code></pre>"},{"location":"part1-coding/08-advanced-patterns/#segment-tree","title":"Segment Tree","text":"<p>See dedicated section: 10-segment-tree-range-query Key Insight: Range decomposition into O(log n) canonical segments for efficient queries.</p>"},{"location":"part1-coding/08-advanced-patterns/#monotonic-stackdeque","title":"Monotonic Stack/Deque","text":""},{"location":"part1-coding/08-advanced-patterns/#mathematical-foundation_1","title":"Mathematical Foundation","text":"<p>Monotonicity Invariant: Maintain stack/deque where elements are in monotonic order. When processing element x, remove all elements that violate monotonicity.</p> <p>Amortized Analysis: Each element enters and exits the structure at most once, giving O(n) total complexity for n operations.</p> <p>Applications: Next greater element, sliding window maximum, largest rectangle in histogram.</p>"},{"location":"part1-coding/08-advanced-patterns/#advanced-dp-patterns","title":"Advanced DP Patterns","text":""},{"location":"part1-coding/08-advanced-patterns/#bitmask-dp","title":"Bitmask DP","text":"<p>State Compression: Use bitmask to represent subset states. For n items, 2\u207f possible states. Complexity: O(2\u207f \u00d7 n) typical, used for TSP, subset enumeration</p>"},{"location":"part1-coding/08-advanced-patterns/#digit-dp","title":"Digit DP","text":"<p>Constraint Satisfaction: Count numbers satisfying digit-based constraints without explicit enumeration. State: (position, tight_bound, constraint_flags) Complexity: O(log N \u00d7 states)</p>"},{"location":"part1-coding/08-advanced-patterns/#tree-dp","title":"Tree DP","text":"<p>Optimal Substructure on Trees: Each subtree can be solved independently, then combined optimally. Root Selection: Sometimes requires re-rooting technique for all-pairs problems. Complexity: O(n) for most tree DP problems</p>"},{"location":"part1-coding/08-advanced-patterns/#interval-dp","title":"Interval DP","text":"<p>Optimal Parenthesization: Break interval [i,j] at all possible points k, solve subproblems [i,k] and [k+1,j]. Recurrence: dp[i][j] = min(dp[i][k] + dp[k+1][j] + cost(i,k,j)) Complexity: O(n\u00b3) typical</p>"},{"location":"part1-coding/08-advanced-patterns/#string-algorithms","title":"String Algorithms","text":""},{"location":"part1-coding/08-advanced-patterns/#kmp-knuth-morris-pratt","title":"KMP (Knuth-Morris-Pratt)","text":"<p>Failure Function: Precompute longest proper prefix which is also suffix for each position. No Backtracking: Never re-examine text characters, achieving O(n+m) complexity.</p>"},{"location":"part1-coding/08-advanced-patterns/#rabin-karp-rolling-hash","title":"Rabin-Karp Rolling Hash","text":"<p>Polynomial Hash: h(s) = \u03a3 s[i] \u00d7 p^i mod M where p is prime, M is large prime. Rolling Property: h(s[1..k]) = (h(s[0..k-1]) - s[0]) / p + s[k] \u00d7 p^(k-1) Complexity: O(n+m) average, O(nm) worst case</p>"},{"location":"part1-coding/08-advanced-patterns/#manachers-algorithm","title":"Manacher's Algorithm","text":"<p>Palindrome Centers: Transform string to handle even/odd length palindromes uniformly. Linear Scan: Use previously computed palindrome information to avoid redundant checks. Complexity: O(n) time and space</p>"},{"location":"part1-coding/08-advanced-patterns/#visual-demonstrations","title":"Visual Demonstrations","text":""},{"location":"part1-coding/08-advanced-patterns/#union-find-step-by-step-n6","title":"Union-Find Step-by-Step (n=6)","text":"<pre><code>Initial: [0,1,2,3,4,5] \u2192 Union(1,2) \u2192 Union(3,4) \u2192 Union(1,3)\n\n0 1 2 3 4 5    0 1\u25002 3 4 5    0 1\u25002 3\u25004 5    0    1     5\n\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf    \u25cf \u25cf\u2500\u25cf \u25cf \u25cf \u25cf    \u25cf \u25cf\u2500\u25cf \u25cf\u2500\u25cf \u25cf    \u25cf    \u2502     \u25cf\n                                              \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n                                              2       3\n                                              \u25cf       \u2502\n                                                      4\n                                                      \u25cf\n\nPath Compression: 4\u21923\u21921 becomes 4\u21921 (direct)\n</code></pre>"},{"location":"part1-coding/08-advanced-patterns/#monotonic-stack-visualization","title":"Monotonic Stack Visualization","text":"<pre><code>Next Greater Element for [2,1,2,4,3,1]:\n\nStep 1: Process 2    Step 2: Process 1    Step 3: Process 2\nStack: [2]           Stack: [2,1]         Stack: [2] (pop 1)\nResult: [-1]         Result: [-1,-1]      Result: [-1,2,-1]\n\nStep 4: Process 4    Step 5: Process 3    Step 6: Process 1\nStack: [4] (pop all) Stack: [4,3]         Stack: [4,3,1]\nResult: [-1,2,4,-1]  Result: [-1,2,4,-1,4] Result: [-1,2,4,-1,4,-1]\n\nMonotonic Property: Stack maintains decreasing order\n</code></pre> <p>FAANG Applications: Number of Islands II, Word Search II, Sliding Window Maximum, Range Sum Queries, Longest Palindromic Substring</p>"},{"location":"part1-coding/10-segment-tree-range-query/","title":"Segment Tree \u2014 Range Query, Point Update","text":""},{"location":"part1-coding/10-segment-tree-range-query/#mathematical-reasoning","title":"Mathematical Reasoning","text":"<p>Range Query Decomposition: Any range [l,r] can be decomposed into O(log n) canonical segments in a balanced binary tree. Each node represents a range and stores aggregate information.</p> <p>Tree Structure: Complete binary tree where leaves represent array elements and internal nodes store aggregate values (sum, min, max, etc.) of their children's ranges.</p> <p>Query Efficiency: Any range query touches at most 2\u00d7\u2308log\u2082 n\u2309 nodes by decomposing the query range into disjoint segments that align with tree structure.</p> <p>Update Propagation: Point updates affect exactly \u2308log\u2082 n\u2309 nodes along the path from leaf to root, maintaining tree invariants.</p> <p>Lazy Propagation: Defers range updates using lazy flags, achieving O(log n) range updates by pushing updates down only when necessary.</p> <p>Complexity: Time O(log n) per query/update, O(n) build, Space O(n)</p>"},{"location":"part1-coding/10-segment-tree-range-query/#visual-representation","title":"Visual Representation","text":"<pre><code>Array: [1, 3, 5, 7, 9, 11]\nSegment Tree for Range Sum Queries:\n\n                    36\n                 [0,5]\n                /      \\\n            9              27\n         [0,2]          [3,5]\n        /     \\        /     \\\n      4         5    16       11\n   [0,1]     [2,2] [3,4]   [5,5]\n   /   \\              /   \\\n  1     3           7     9\n[0,0] [1,1]      [3,3] [4,4]\n\nQuery [1,4]: Traverse tree, combine segments [1,1], [2,2], [3,4]\nPath: Root \u2192 Left \u2192 Right(leaf) + Right(leaf) + Right \u2192 Left\nResult: 3 + 5 + 16 = 24\n</code></pre>"},{"location":"part1-coding/10-segment-tree-range-query/#range-decomposition-example","title":"Range Decomposition Example","text":"<pre><code>Query range [2,4] on array of size 6:\n\nOriginal range: [2,4]\nTree decomposition:\n- Node [2,2]: covers index 2 \u2192 value 5\n- Node [3,4]: covers indices 3,4 \u2192 value 16\nTotal: 5 + 16 = 21\n\nEfficient: Only 2 nodes touched instead of 3 individual elements\n</code></pre>"},{"location":"part1-coding/10-segment-tree-range-query/#algorithm-invariant","title":"Algorithm Invariant","text":"<p>Tree Invariant: Each internal node stores the aggregate of all elements in its subtree range, enabling efficient range queries through tree traversal.</p>"},{"location":"part1-coding/10-segment-tree-range-query/#pseudocode","title":"Pseudocode","text":"<pre><code>build:\n  n = power_of_two &gt;= len(a); tree size = 2n\n  fill leaves with a; for i=n-1..1: tree[i]=merge(tree[2i], tree[2i+1])\n\nupdate(i, val):\n  p = n+i; tree[p]=val; p//=2 while p&gt;=1: tree[p]=merge(children); p//=2\n\nquery(l,r):  # inclusive\n  l+=n; r+=n; res=identity\n  while l&lt;=r:\n    if l odd: res=merge(res, tree[l]); l++\n    if r even: res=merge(res, tree[r]); r--\n    l//=2; r//=2\n  return res\n</code></pre> \ud83d\udc0d Python Implementation <pre><code>class SegmentTree:\n    def __init__(self, nums):\n        n = len(nums); self.n = 1\n        while self.n &lt; n: self.n &lt;&lt;= 1\n        self.tree = [0] * (2 * self.n)\n        for i, v in enumerate(nums):\n            self.tree[self.n + i] = v\n        for i in range(self.n - 1, 0, -1):\n            self.tree[i] = self.tree[2 * i] + self.tree[2 * i + 1]\n\n    def update(self, idx, val):\n        i = self.n + idx\n        self.tree[i] = val\n        i //= 2\n        while i &gt;= 1:\n            self.tree[i] = self.tree[2 * i] + self.tree[2 * i + 1]\n            i //= 2\n\n    def query(self, l, r):\n        l += self.n; r += self.n\n        res = 0\n        while l &lt;= r:\n            if l &amp; 1:\n                res += self.tree[l]; l += 1\n            if not (r &amp; 1):\n                res += self.tree[r]; r -= 1\n            l //= 2; r //= 2\n        return res\n</code></pre> \u26a1 C++ Implementation <pre><code>struct SegmentTree {\n    int n; vector&lt;int&gt; t;\n    SegmentTree(const vector&lt;int&gt;&amp; a){\n        int sz=a.size(); n=1; while(n&lt;sz) n&lt;&lt;=1;\n        t.assign(2*n,0);\n        for(int i=0;i&lt;sz;i++) t[n+i]=a[i];\n        for(int i=n-1;i&gt;=1;--i) t[i]=t[2*i]+t[2*i+1];\n    }\n    void update(int idx,int val){\n        int i=n+idx; t[i]=val; i&gt;&gt;=1;\n        while(i&gt;=1){ t[i]=t[2*i]+t[2*i+1]; i&gt;&gt;=1; }\n    }\n    int query(int l,int r){\n        l+=n; r+=n; int res=0;\n        while(l&lt;=r){\n            if(l&amp;1) res+=t[l++];\n            if(!(r&amp;1)) res+=t[r--];\n            l&gt;&gt;=1; r&gt;&gt;=1;\n        }\n        return res;\n    }\n};\n</code></pre> \u2615 Java Implementation <pre><code>public class SegmentTree {\n    int n; int[] t;\n    public SegmentTree(int[] a){\n        n=1; while(n&lt;a.length) n&lt;&lt;=1;\n        t=new int[2*n];\n        for(int i=0;i&lt;a.length;i++) t[n+i]=a[i];\n        for(int i=n-1;i&gt;=1;--i) t[i]=t[2*i]+t[2*i+1];\n    }\n    public void update(int idx,int val){\n        int i=n+idx; t[i]=val; i&gt;&gt;=1;\n        while(i&gt;=1){ t[i]=t[2*i]+t[2*i+1]; i&gt;&gt;=1; }\n    }\n    public int query(int l,int r){\n        l+=n; r+=n; int res=0;\n        while(l&lt;=r){\n            if((l&amp;1)==1) res+=t[l++];\n            if((r&amp;1)==0) res+=t[r--];\n            l&gt;&gt;=1; r&gt;&gt;=1;\n        }\n        return res;\n    }\n}\n</code></pre> \ud83d\ude80 Go Implementation <pre><code>type SegmentTree struct {\n    n    int\n    tree []int\n}\n\nfunc NewSegmentTree(nums []int) *SegmentTree {\n    n := 1\n    for n &lt; len(nums) {\n        n &lt;&lt;= 1\n    }\n\n    tree := make([]int, 2*n)\n    for i, v := range nums {\n        tree[n+i] = v\n    }\n\n    for i := n - 1; i &gt;= 1; i-- {\n        tree[i] = tree[2*i] + tree[2*i+1]\n    }\n\n    return &amp;SegmentTree{n: n, tree: tree}\n}\n\nfunc (st *SegmentTree) Update(idx, val int) {\n    i := st.n + idx\n    st.tree[i] = val\n    i &gt;&gt;= 1\n\n    for i &gt;= 1 {\n        st.tree[i] = st.tree[2*i] + st.tree[2*i+1]\n        i &gt;&gt;= 1\n    }\n}\n\nfunc (st *SegmentTree) Query(l, r int) int {\n    l += st.n\n    r += st.n\n    res := 0\n\n    for l &lt;= r {\n        if l&amp;1 == 1 {\n            res += st.tree[l]\n            l++\n        }\n        if r&amp;1 == 0 {\n            res += st.tree[r]\n            r--\n        }\n        l &gt;&gt;= 1\n        r &gt;&gt;= 1\n    }\n\n    return res\n}\n</code></pre>"},{"location":"part2-system-design/","title":"System Design \u2014 Zero to Hero","text":"<p>Mathematical foundations + real-world patterns + war stories = interview confidence.</p>"},{"location":"part2-system-design/#learning-path","title":"Learning Path","text":"<ol> <li>Foundations \u2014 Latency math, throughput engineering, availability calculations</li> <li>Core Infrastructure \u2014 Caching strategies, load balancing, message queues  </li> <li>Data Layer \u2014 Sharding math, replication patterns, consistency models</li> <li>Operations \u2014 Observability, reliability engineering, security frameworks</li> <li>Cloud Mapping \u2014 AWS/GCP/Azure service equivalents with cost models</li> <li>Case Studies \u2014 Real numbers from bit.ly, WhatsApp, YouTube, Stripe, Airbnb scale</li> <li>Failure Engineering \u2014 Circuit breakers, chaos patterns, incident response</li> <li>Modern Patterns \u2014 Event sourcing, service mesh, serverless, data mesh</li> <li>War Stories \u2014 Real outages, scaling disasters, lessons learned</li> </ol>"},{"location":"part2-system-design/#tools-calculators","title":"Tools &amp; Calculators","text":"<ul> <li>capacity_calculator.py \u2014 Little's Law, cache sizing, cost estimation</li> <li>estimation_framework.md \u2014 10-minute systematic approach  </li> <li>tradeoff_decisions.md \u2014 Decision trees for architecture choices</li> </ul>"},{"location":"part2-system-design/#success-metrics","title":"Success Metrics","text":"<ul> <li>Estimate within 2x of actual numbers for known systems</li> <li>Identify 3+ applicable patterns per problem in &lt;5 minutes  </li> <li>Complete system design in 35-40 minutes with deep dives</li> <li>Score 3.5+/4.0 on mock interview rubrics</li> </ul>"},{"location":"part2-system-design/#interview-authenticity","title":"Interview Authenticity","text":"<p>Replace \"typically we would...\" with \"when I designed X at Y, we discovered...\" Use specific numbers: \"cache hit ratios below 85% indicate poor key design\" Reference real incidents: \"similar to the 2019 GitHub outage caused by...\"</p>"},{"location":"part2-system-design/estimation_framework/","title":"Estimation Framework \u2014 10-Minute Flow","text":"<ol> <li>Traffic math: Peak QPS = daily volume / 86,400 \u00d7 peak factor (2-5x). Concurrency = QPS \u00d7 latency (s).  </li> <li>Storage: (objects/day \u00d7 avg size) \u00d7 retention. Add 20-30% overhead for metadata/replication.  </li> <li>Hotset vs coldset: Assume 20% of keys drive 80% traffic; cache size = hot objects \u00d7 size \u00d7 overhead.  </li> <li>Latency budget: Network (WAN 50-150ms) + app (5-20ms) + datastore (1-10ms cache, 5-50ms DB) + queueing.  </li> <li>Availability: A_system = \u03a0 A_component. Redundancy math: A=1-(1-a)^N. Target 99.9% unless otherwise stated.  </li> <li>Read/write mix: Route reads to cache/replicas, writes to primaries; pick quorum config (N,R,W) to match consistency.  </li> <li>Back-of-envelope infra: </li> <li>Cache: RPS_cache = hit_ratio \u00d7 reads; size from hotset.  </li> <li>DB: writes/QPS \u00f7 per-node capacity; add replicas = ceiling(load / capacity).  </li> <li>Queue: \u03bb, \u03bc \u21d2 \u03c1=\u03bb/\u03bc &lt; 0.7.  </li> <li>Cost sanity: Storage $0.02\u20130.03/GB-month (object), $0.08/GB-month (block), egress $0.09/GB first 10TB.  </li> <li>Bottlenecks: Identify first limit (DB QPS, cache size, network egress, P99 latency).  </li> <li>Narrate constraints: \u201cAt 2K QPS writes and 90/10 read/write, primary handles 200 writes/s; I\u2019ll add 3 replicas for reads and a 4GB Redis hotset.\u201d</li> </ol>"},{"location":"part2-system-design/tradeoff_decisions/","title":"Tradeoff Decision Cheats","text":"<ul> <li>SQL vs NoSQL: Strong consistency + joins + analytics \u2192 SQL. Massive scale + simple access + multi-region active-active \u2192 NoSQL (Dynamo/Cassandra).  </li> <li>Cache strategy: Read-heavy with temporal locality \u2192 Redis/Memcached. Write-heavy or strict consistency \u2192 database first with read-through or write-through cache.  </li> <li>Queues vs sync calls: Spiky traffic, retry safety, decouple failures \u2192 queue/stream. Low-latency user path with tight SLAs \u2192 synchronous + circuit breakers.  </li> <li>Sharding timing: Shard when CPU/io maxed AND traffic patterns stable. Premature sharding increases complexity and ops cost.  </li> <li>CDN/edge: Static assets and media \u2192 CDN by default. Dynamic content \u2192 edge compute only when latency/egress justify added complexity.  </li> <li>Serverless vs containers: &lt;30% avg utilization, spiky workloads \u2192 serverless. Steady traffic or heavy dependencies \u2192 containers/VMs.  </li> <li>Global vs regional: User latency &lt;100ms global? \u2192 multi-region active-active with conflict resolution. Otherwise single-region + DR.  </li> <li>Consistency level: Money/ledger \u2192 strong + idempotency keys. Social feed/search \u2192 eventual + background repair.  </li> <li>Observability cost: Sample traces (1-5%), pre-aggregate metrics; logs to cold storage with retention tiers.  </li> <li>Security posture: Public APIs \u2192 authN/authZ, rate limits, WAF. PII/PCI \u2192 tokenization, encryption at rest+transit, least privilege, audit trails.</li> </ul>"},{"location":"part2-system-design/01-foundations/","title":"Foundations \u2014 Latency, Throughput, Availability","text":""},{"location":"part2-system-design/01-foundations/#latency-breakdown-real-numbers","title":"Latency Breakdown (Real Numbers)","text":"<p>Network: LAN 0.1ms, WAN 50-150ms, Cross-continent 200ms+ Database: Index lookup 1ms, Full scan 100ms+, Join 10-100ms Cache: In-memory 0.1ms, Redis 1ms, Memcached 0.5ms Disk: SSD 0.1ms, HDD 10ms, Network storage 1-5ms L_total = \u03a3 component_i + network + queueing_delay</p> <pre><code>flowchart TB\nUser --&gt; CDN[CDN: 10-30ms]\nCDN --&gt; LB[LB: 1-3ms]\nLB --&gt; Cache[Cache: 0.5-2ms]\nCache --&gt;|hit| App[App: 5-15ms]\nCache --&gt;|miss| DB[DB: 5-50ms]\nApp --&gt; User</code></pre>"},{"location":"part2-system-design/01-foundations/#throughput-engineering","title":"Throughput Engineering","text":"<p>Little's Law: N = \u03bb \u00d7 L (users = arrival_rate \u00d7 response_time) Utilization target: \u03c1 &lt; 0.7 for stable performance, \u03c1 &lt; 0.5 for burst capacity Queue theory: Response time explodes as \u03c1 \u2192 1.0 Bottleneck identification: Throughput = min(component_throughputs)</p>"},{"location":"part2-system-design/01-foundations/#availability-math","title":"Availability Math","text":"<p>SLA targets: 99% = 3.65 days/year, 99.9% = 8.76 hours/year, 99.99% = 52.6 min/year Redundancy: A_system = 1 - (1-A_component)^N for N independent components Dependency chains: A_chain = A1 \u00d7 A2 \u00d7 ... \u00d7 An (multiplicative) Error budgets: Remaining downtime = SLA_target - actual_downtime</p>"},{"location":"part2-system-design/01-foundations/#cap-theorem-in-practice","title":"CAP Theorem in Practice","text":"<p>Partition tolerance: Always required in distributed systems CP systems: RDBMS, etcd, Consul (sacrifice availability during partitions) AP systems: DynamoDB, Cassandra, DNS (sacrifice consistency during partitions) Consistency spectrum: Strong \u2192 Bounded staleness \u2192 Session \u2192 Eventual</p>"},{"location":"part2-system-design/01-foundations/#quorum-mathematics","title":"Quorum Mathematics","text":"<p>Strong consistency: R + W &gt; N (read + write quorums overlap) High availability: R + W \u2264 N (can tolerate failures) Common configs: N=3, R=2, W=2 (strong) vs N=3, R=1, W=1 (fast) Latency impact: Quorum latency = P(N-R+1) percentile of replica latencies</p>"},{"location":"part2-system-design/02-caching-lb-queues/","title":"Caching, Load Balancing, Queues","text":""},{"location":"part2-system-design/02-caching-lb-queues/#equations-to-anchor","title":"Equations to anchor","text":"<ul> <li>Cache hit ratio (\u03b7): E[L]=\u03b7L1+(1-\u03b7)L2; maximize \u03b7 given memory.</li> <li>LB: consistent hashing to minimize remaps on scale-out.</li> <li>Queues: M/M/1: W=\u03c1/(\u03bc-\u03bb). Keep \u03c1&lt;1; add backpressure or rate limits if \u03bb&gt;\u03bc.</li> </ul>"},{"location":"part2-system-design/02-caching-lb-queues/#how-to-talk-about-it","title":"How to talk about it","text":"<ul> <li>\u201cWe measured hotset as top 20% keys; with \u03b7=0.9 we cut DB traffic by 10x. At $JOB we also capped TTL to avoid serving cold data after deploys.\u201d</li> <li>\u201cFor load balancing I default to L4 round-robin; when node churn is high, switch to consistent hashing to avoid 30% cache churn.\u201d</li> <li>\u201cQueues absorb spikes; I size workers so \u03c1 stays under 0.7, and enforce dead-letter with idempotent consumers so retries don\u2019t double-charge.\u201d</li> </ul>"},{"location":"part2-system-design/02-caching-lb-queues/#failure-modes-to-mention","title":"Failure modes to mention","text":"<ul> <li>Cache stampede: add jittered TTL and request coalescing.</li> <li>Load balancer hot keys: consistent hashing + virtual nodes to smooth distribution.</li> <li>Queue backlog: backpressure to clients, drop non-critical classes, alert on age not just depth.</li> </ul> <pre><code>flowchart LR\nClient --&gt; LB[Load Balancer]\nLB --&gt; Cache[Redis/Memcached]\nCache --&gt;|hit| App\nCache --&gt;|miss| DB[(DB)]\nApp --&gt; Queue[(Queue)]\nQueue --&gt; Workers\nWorkers --&gt; DB</code></pre>"},{"location":"part2-system-design/03-sharding-replication-quorums/","title":"Sharding, Replication, Quorums","text":""},{"location":"part2-system-design/03-sharding-replication-quorums/#core-math","title":"Core math","text":"<ul> <li>Shard function: s(k)=hash(k) mod n; keep load balance near uniform.</li> <li>Replication to increase availability; independence assumption gives A=1-p^N.</li> <li>Quorums: R+W&gt;N ensures intersection, hence strong consistency.</li> </ul>"},{"location":"part2-system-design/03-sharding-replication-quorums/#interview-narration","title":"Interview narration","text":"<ul> <li>\u201cWe stayed single-shard until CPU &gt;70% and p99 &gt; 150ms; then we hash(user_id) with 128 virtual nodes to avoid hotspots.\u201d</li> <li>\u201cReplicas give 1-(1-a)^N availability; we ran 3 AZ replicas which pushed single-node 99.5% to 99.999% cluster availability.\u201d</li> <li>\u201cFor N=3 we used R=1,W=2 on reads-heavy paths; for money movement we flip to R=2,W=2 to keep strong consistency under failure.\u201d</li> </ul>"},{"location":"part2-system-design/03-sharding-replication-quorums/#gotchas","title":"Gotchas","text":"<ul> <li>Rebalancing causes thundering herds if caches are keyed by physical shard; use indirection/consistent hashing ring.</li> <li>Cross-shard joins are expensive: denormalize or move to search index.</li> <li>Split-brain risk: require quorum ACKs and a fencing token on leader election.</li> </ul> <pre><code>flowchart LR\n    Client --&gt; Router[Shard Router]\n    Router --&gt; S1[\"Shard A (N=3)\"]\n    Router --&gt; S2[\"Shard B (N=3)\"]\n    S1 --&gt; R1a[Replica 1]\n    S1 --&gt; R1b[Replica 2]\n    S1 --&gt; R1c[Replica 3]\n    S2 --&gt; R2a[Replica 1]\n    S2 --&gt; R2b[Replica 2]\n    S2 --&gt; R2c[Replica 3]</code></pre>"},{"location":"part2-system-design/04-observability-reliability-security/","title":"Observability, Reliability, Security","text":""},{"location":"part2-system-design/04-observability-reliability-security/#what-to-instrument","title":"What to instrument","text":"<ul> <li>Metrics/Traces/Logs: define P50/P95/P99, error budgets, dashboards; sample traces (1-5%), log to cold storage.</li> <li>Golden signals: latency, traffic, errors, saturation. Alert on SLO burn, not just thresholds.</li> </ul>"},{"location":"part2-system-design/04-observability-reliability-security/#reliability-moves","title":"Reliability moves","text":"<ul> <li>Circuit breakers + retries with jitter; timeouts per hop; bulkheads for noisy neighbors.</li> <li>Regional isolation tests monthly; chaos drills on caches/DB/network to prove failover paths.</li> </ul>"},{"location":"part2-system-design/04-observability-reliability-security/#security-stance","title":"Security stance","text":"<ul> <li>AuthN/AuthZ everywhere, TLS in transit, KMS-backed at rest, key rotation.</li> <li>Principle of least privilege for services; WAF + rate limits on public edges.</li> <li>\u201cAt $JOB we cut auth latency by 20ms by moving JWT validation to the edge; we still centralized policy in OPA.\u201d</li> </ul> <pre><code>flowchart LR\nsubgraph Observability\nMetrics --&gt; Dash[Dashboards]\nTraces --&gt; Dash\nLogs --&gt; SIEM\nend\nsubgraph Reliability\nApp --&gt; CB[Circuit Breaker]\nCB --&gt; Retry[Retries+Timeouts]\nRetry --&gt; App\nend\nsubgraph Security\nEdge[Edge/WAF] --&gt; Auth[AuthN/Z]\nAuth --&gt; App\nend</code></pre>"},{"location":"part2-system-design/05-cloud-mapping/","title":"Cloud Mapping (AWS / Azure / GCP)","text":"Function AWS Azure GCP LB ALB/NLB App Gateway/Front Door Cloud LB Compute EC2/ECS/EKS VMSS/AKS GCE/GKE Cache ElastiCache Azure Cache for Redis Memorystore Queue/Stream SQS/MSK Service Bus/Event Hubs Pub/Sub Object Store S3 Blob Cloud Storage NoSQL DynamoDB Cosmos DB Firestore SQL RDS/Aurora Azure SQL DB Cloud SQL"},{"location":"part2-system-design/05-cloud-mapping/#how-to-choose-in-the-room","title":"How to choose in the room","text":"<ul> <li>Latency classes: CDN/edge (&lt;50ms), managed cache (1-2ms), managed DB (5-20ms), cross-region (70-150ms). Keep user-path under 200ms P95.</li> <li>Cost cues: object storage ~$0.02/GB-mo, cache memory ~$0.03-0.05/GB-hr, cross-region egress ~$0.12/GB. Mention when egress dominates.</li> <li>Default stacks:  </li> <li>Read-heavy + simple access \u2192 Cloud LB + CDN + Redis + Dynamo/Cosmos/Firestore.  </li> <li>SQL with HA \u2192 RDS/Aurora, AZ multi-AZ, read replicas; failover tested quarterly.  </li> <li>Streaming \u2192 MSK/Event Hubs/Pub/Sub with compacted topics for idempotent consumers.</li> <li>Vendor quirks: DynamoDB autoscaling lag (pre-provision for spikes), Azure Cosmos RU budgeting, GCP per-project quota ceilings. State the mitigations you\u2019d apply.</li> </ul> <pre><code>flowchart LR\nUser --&gt; Edge[CDN/Edge]\nEdge --&gt; LB[Cloud LB]\nLB --&gt; Cache[Managed Redis]\nCache --&gt;|hit| App\nCache --&gt;|miss| DB[(SQL/NoSQL)]\nApp --&gt; Stream[(Kafka / Event Hubs / PubSub)]\nStream --&gt; Consumers</code></pre>"},{"location":"part2-system-design/06-case-studies/","title":"Case Studies \u2014 With Real Numbers","text":""},{"location":"part2-system-design/06-case-studies/#1-url-shortener-bitly-scale","title":"1) URL Shortener (bit.ly scale)","text":"<p>Scale: 100M URLs/day, 10:1 read:write ratio QPS: Write: 1,157/s, Read: 11,570/s Storage: 100M \u00d7 (7 bytes key + 100 bytes URL) = 10.7GB/day = 3.9TB/year Cache: Target \u03b7=0.9 hit ratio \u2192 90% of 11,570 = 10,413 req/s from cache Memory needed: Hot URLs (20% of total) \u00d7 107 bytes \u2248 2.1GB cache (round to 4GB incl. overhead) Database: Read replicas = ceil(1,157 / 1000) = 2 replicas minimum</p> <pre><code>flowchart LR\nClient --&gt; CDN\nCDN --&gt; Cache\nCache --&gt;|hit| App\nCache --&gt;|miss| DB[(Primary + Replicas)]\nDB --&gt; Replicas[Read Replicas]\nApp --&gt; Analytics[(Analytics/ETL)]</code></pre>"},{"location":"part2-system-design/06-case-studies/#2-whatsapp-like-messaging-1b-users","title":"2) WhatsApp-like Messaging (1B users)","text":"<p>Scale: 1B users, 50 messages/user/day = 50B messages/day QPS: 50B / 86400 = 578K messages/sec peak Storage: 50B \u00d7 1KB avg = 50TB/day = 18PB/year Delivery: 99.9% within 100ms, 99.99% within 1s Partitioning: Hash(user_id) mod 1000 shards Replication: 3x for availability, async cross-region</p>"},{"location":"part2-system-design/06-case-studies/#3-youtube-lite-100m-hours-watchedday","title":"3) YouTube-lite (100M hours watched/day)","text":"<p>Upload: 500 hours/min = 30K videos/hour Storage: 30K \u00d7 1GB avg = 30TB/hour raw, 150TB/hour transcoded Transcoding: 5 formats \u00d7 2x realtime = 10x compute cost CDN: 100M hours \u00d7 1Mbps avg \u2248 4.2Tbps sustained global bandwidth Cost breakdown: Storage $2M/month, Compute $500K/month, CDN $3M/month</p>"},{"location":"part2-system-design/06-case-studies/#4-stripe-like-payments-10m-transactionsday","title":"4) Stripe-like Payments (10M transactions/day)","text":"<p>QPS: 10M / 86400 = 116 TPS average, 500 TPS peak Latency: P95 &lt; 200ms, P99 &lt; 500ms Consistency: Strong for money movement, eventual for analytics Idempotency: 24-hour key retention, SHA-256 hash Compliance: PCI DSS Level 1, SOX controls, audit trails Fraud detection: &lt;50ms ML inference, 0.1% false positive rate</p>"},{"location":"part2-system-design/06-case-studies/#code-example-idempotency-key-generation","title":"Code Example: Idempotency Key Generation","text":"<pre><code>import hashlib\nimport json\n\ndef generate_idempotency_key(payload: dict) -&gt; str:\n    \"\"\"\n    Creates a stable idempotency key from a request payload.\n    \"\"\"\n    # Use a canonical representation of the payload (sorted keys)\n    payload_str = json.dumps(payload, sort_keys=True)\n    return hashlib.sha256(payload_str.encode('utf-8')).hexdigest()\n\n# Example for a payment request\npayment_request = {\"amount\": 1000, \"currency\": \"usd\", \"user_id\": \"user_123\"}\nidempotency_key = generate_idempotency_key(payment_request)\n# The client would send this key in the 'Idempotency-Key' header.\n</code></pre>"},{"location":"part2-system-design/06-case-studies/#5-global-booking-airbnb-scale","title":"5) Global Booking (Airbnb scale)","text":"<p>Inventory: 7M listings, 150M users, 500M searches/day Search QPS: 500M / 86400 = 5,787/s average, 20K/s peak Geo-sharding: 50 regions, route by user location Consistency: Eventual for search, strong for booking Cache layers: L1 (CDN) \u2192 L2 (Redis) \u2192 L3 (Elasticsearch) \u2192 DB SLA: 99.95% availability, &lt;100ms search latency P95</p>"},{"location":"part2-system-design/07-failure-engineering/","title":"Failure Engineering \u2014 Chaos, Incidents, Capacity","text":""},{"location":"part2-system-design/07-failure-engineering/#circuit-breaker-math","title":"Circuit Breaker Math","text":"<p>Failure threshold: F_threshold = error_rate \u00d7 time_window Recovery condition: success_rate &gt; 0.8 for 30s Exponential backoff: delay = base_delay \u00d7 2^attempt (max 60s)</p> <pre><code>State transitions:\nCLOSED \u2192 OPEN: failures &gt; threshold\nOPEN \u2192 HALF_OPEN: timeout expires  \nHALF_OPEN \u2192 CLOSED: success_rate &gt; 0.8\n</code></pre>"},{"location":"part2-system-design/07-failure-engineering/#capacity-planning-formulas","title":"Capacity Planning Formulas","text":"<p>Little's Law: N = \u03bb \u00d7 L (concurrent users = arrival_rate \u00d7 latency) Utilization target: \u03c1 = 0.7 (70% max for stable performance) Scaling trigger: CPU &gt; 70% OR memory &gt; 80% OR queue_depth &gt; 100</p>"},{"location":"part2-system-design/07-failure-engineering/#real-incident-patterns","title":"Real Incident Patterns","text":"<p>Database cascade failure: Connection pool exhaustion \u2192 app timeouts \u2192 user retry storm Cache stampede: Popular key expires \u2192 N requests hit DB \u2192 DB overload Thundering herd: Service restart \u2192 all clients reconnect simultaneously</p>"},{"location":"part2-system-design/07-failure-engineering/#sla-math","title":"SLA Math","text":"<p>Availability budget: 99.9% = 8.76h downtime/year = 43.8min/month Error budget burn rate: current_error_rate / sla_error_rate MTTR target: &lt; 15min for P0, &lt; 2h for P1, &lt; 24h for P2</p>"},{"location":"part2-system-design/07-failure-engineering/#disaster-recovery","title":"Disaster Recovery","text":"<p>RTO calculation: detection_time + failover_time + validation_time RPO constraint: max_data_loss = backup_frequency + replication_lag Cross-region latency: US-East to US-West = 70ms, US to EU = 150ms</p> <pre><code>sequenceDiagram\nparticipant User\nparticipant Service\nparticipant DBPrimary\nparticipant DBReplica\nparticipant DR[DR Region]\n\nUser-&gt;&gt;Service: Request\nService-&gt;&gt;DBPrimary: Write\nDBPrimary--&gt;&gt;Service: Ack\nDBPrimary--&gt;&gt;DBReplica: Replicate\nService--&gt;&gt;User: Response\nNote over Service,DBPrimary: Circuit breaker trips if error rate &gt; threshold\nDBPrimary--x Service: Failure\nService-&gt;&gt;DR: Failover to DR region (RTO)</code></pre>"},{"location":"part2-system-design/08-modern-patterns/","title":"Modern Architecture Patterns","text":""},{"location":"part2-system-design/08-modern-patterns/#event-sourcing-cqrs","title":"Event Sourcing + CQRS","text":"<p>Event store size: events_per_day \u00d7 avg_event_size \u00d7 retention_days Projection lag: acceptable_staleness &lt; 100ms for real-time, &lt; 5s for analytics Snapshot frequency: every 1000 events OR daily, whichever is smaller</p> <pre><code>Command: UserRegistered \u2192 Event Store \u2192 Projection Updates\nQuery: Read from optimized projections, not event stream\n</code></pre> <p>Narration: \u201cWe used event sourcing when auditability mattered; projections let us serve sub-10ms reads while writes stayed append-only. Operationally, snapshots kept cold replays under 5 minutes.\u201d</p>"},{"location":"part2-system-design/08-modern-patterns/#service-mesh-economics","title":"Service Mesh Economics","text":"<p>Sidecar overhead: +20ms latency, +50MB memory per service mTLS cost: +5-10ms per hop, +15% CPU for encryption Observability tax: +2-5% CPU for tracing, +10MB memory for metrics</p> <p>Narration: \u201cMesh only paid off once we had 20+ services and multi-team ownership. Before that, the sidecar tax was wasted.\u201d</p>"},{"location":"part2-system-design/08-modern-patterns/#serverless-patterns","title":"Serverless Patterns","text":"<p>Cold start penalty: 100-500ms for JVM, 10-50ms for Node.js, 1-5ms for Go Concurrent execution limit: 1000 default (AWS), scale to 10K+ with limits increase Cost crossover: serverless cheaper below 30% utilization, containers cheaper above</p> <p>Narration: \u201cWe kept cron/ETL on Lambda; user-facing APIs moved to containers to dodge cold starts and get predictable latency.\u201d</p>"},{"location":"part2-system-design/08-modern-patterns/#data-mesh-principles","title":"Data Mesh Principles","text":"<p>Domain ownership: Each team owns their data products end-to-end Federated governance: Common standards, local implementation Self-serve platform: Data infrastructure as a service, not shared databases</p> <p>Narration: \u201cWe enforced contracts via schemas + quality SLAs; consumers could veto changes that broke them.\u201d</p>"},{"location":"part2-system-design/08-modern-patterns/#edge-computing-math","title":"Edge Computing Math","text":"<p>CDN cache hit: 85-95% typical, 99%+ for static assets Edge latency: &lt;50ms to 90% of users globally Bandwidth savings: 80-90% reduction in origin traffic with proper caching</p> <p>Narration: \u201cEdge worked when payloads were cacheable or could be precomputed; dynamic personalization still hit origin with feature-flagged rollouts.\u201d</p> <pre><code>flowchart LR\nUser --&gt; Edge[Edge/POP]\nEdge --&gt; Origin[Origin App]\nOrigin --&gt; DB[(DB/Storage)]\nsubgraph Event Sourcing\nCmd[Command] --&gt; ES[Event Store]\nES --&gt; Proj[Projections]\nProj --&gt; Query[Query API]\nend</code></pre>"},{"location":"part2-system-design/09-war-stories/","title":"War Stories &amp; Anti-Patterns","text":""},{"location":"part2-system-design/09-war-stories/#the-great-database-migration-of-2019","title":"The Great Database Migration of 2019","text":"<p>Problem: 50TB MySQL \u2192 PostgreSQL with zero downtime Solution: Dual-write pattern + lag monitoring + gradual traffic shift Lesson: Migration time = data_size / (bandwidth \u00d7 efficiency_factor \u00d7 available_hours) Reality check: 50TB took 6 weeks, not the planned 2 weeks</p>"},{"location":"part2-system-design/09-war-stories/#cache-stampede-at-scale","title":"Cache Stampede at Scale","text":"<p>Incident: Popular cache key expired during Black Friday Impact: 10,000 concurrent requests hit database, 30s response time Fix: Probabilistic early expiration: expire_time - random(0, 60s) Prevention: Cache warming + circuit breakers + request coalescing</p>"},{"location":"part2-system-design/09-war-stories/#the-microservices-monolith","title":"The Microservices Monolith","text":"<p>Anti-pattern: 47 services for a 5-person team Overhead: 2 weeks/quarter just for dependency updates Rule: Start with modular monolith, extract services when team &gt; 8 people Conway's Law: System design mirrors org structure, not the other way around</p>"},{"location":"part2-system-design/09-war-stories/#premature-sharding-disaster","title":"Premature Sharding Disaster","text":"<p>Mistake: Sharded user table at 100K users \"for future scale\" Cost: 6 months of cross-shard query complexity Reality: Vertical scaling handles 10M+ users on modern hardware Lesson: Shard when CPU/memory maxed AND traffic patterns are stable</p>"},{"location":"part2-system-design/09-war-stories/#the-kubernetes-overkill","title":"The Kubernetes Overkill","text":"<p>Scenario: 3-service app deployed on 12-node K8s cluster Monthly cost: $2,400 vs $200 for equivalent VMs Complexity: 40 YAML files, 3 operators, 2 service meshes Sweet spot: K8s pays off with 20+ services OR multi-team deployment needs</p>"},{"location":"part2-system-design/09-war-stories/#vendor-lock-in-escape","title":"Vendor Lock-in Escape","text":"<p>Challenge: Migrate from proprietary NoSQL to open source Timeline: 18 months, $2M engineering cost Strategy: Abstract data layer + parallel writes + gradual cutover Prevention: Multi-cloud from day 1 costs 20% more, saves 10x in exit scenarios</p>"},{"location":"part2-system-design/10-faang-deep-dives/","title":"FAANG Deep Dives \u2014 Real Interview Questions","text":""},{"location":"part2-system-design/10-faang-deep-dives/#metafacebook-scale-problems","title":"Meta/Facebook Scale Problems","text":"<p>News Feed (2.9B users) - Write amplification: 1 post \u2192 1000 friends = 1000 writes to timeline cache - Fan-out strategies: Push (pre-compute) vs Pull (compute on read) vs Hybrid - Celebrity problem: Beyonc\u00e9 posts \u2192 100M fan-outs crash system - Solution: Pull model for celebrities (&gt;1M followers), push for regular users - Numbers: 300M posts/day, 4.5B likes/day, 100TB/day new content</p> <p>Instagram Stories (500M daily users) - Ephemeral storage: 24-hour TTL, optimized for sequential access - Video processing: 15-second clips, 5 quality levels, 2-second segments - Global distribution: 150+ edge locations, 99.9% served from cache - Storage math: 500M users \u00d7 3 stories \u00d7 10MB = 15PB/day (before compression)</p>"},{"location":"part2-system-design/10-faang-deep-dives/#google-scale-problems","title":"Google Scale Problems","text":"<p>Search Index (8.5B pages) - Crawling rate: 20B pages/day, 200K pages/sec sustained - Index sharding: By term frequency + geographic relevance - Query processing: &lt;200ms P99 including network, ranking, personalization - Caching layers: L1 (query results) + L2 (index shards) + L3 (page content)</p> <p>YouTube Recommendations (2B logged-in users) - Candidate generation: 1M videos \u2192 100 candidates in &lt;10ms - Ranking model: 100 candidates \u2192 10 recommendations in &lt;50ms - A/B testing: 1000+ experiments running, 0.1% traffic per test - Cold start: New users get trending + geographic signals</p>"},{"location":"part2-system-design/10-faang-deep-dives/#amazon-scale-problems","title":"Amazon Scale Problems","text":"<p>Prime Video Streaming (200M subscribers) - Bitrate adaptation: 7 quality levels, switch every 2-10 seconds - CDN strategy: 400+ edge locations, 95% cache hit ratio - Encoding pipeline: 1 source \u2192 28 variants (resolution \u00d7 bitrate \u00d7 codec) - Cost optimization: $0.02/GB CDN vs $0.09/GB origin transfer</p> <p>Alexa Voice Processing (100M devices) - Wake word detection: On-device, &lt;500ms latency, 99.9% accuracy - Speech-to-text: Cloud processing, &lt;800ms end-to-end - Intent classification: 100K+ skills, contextual understanding - Privacy: Voice data encrypted, user deletion within 24 hours</p>"},{"location":"part2-system-design/10-faang-deep-dives/#netflix-scale-problems","title":"Netflix Scale Problems","text":"<p>Content Delivery (230M subscribers) - Encoding optimization: Per-title encoding saves 20% bandwidth - Predictive caching: Pre-position content based on viewing patterns - Chaos engineering: Simian Army, failure injection in production - Microservices: 700+ services, 1M+ RPS, 99.99% availability</p>"},{"location":"part2-system-design/10-faang-deep-dives/#apple-scale-problems","title":"Apple Scale Problems","text":"<p>App Store Search (500M weekly users) - Real-time indexing: New apps searchable within 1 hour - Personalization: Download history + device type + location - Fraud detection: ML models detect fake reviews, ratings manipulation - Global consistency: 175 countries, localized results, &lt;100ms latency</p>"},{"location":"part2-system-design/11-ml-systems/","title":"ML Systems Design \u2014 FAANG AI/ML Roles","text":""},{"location":"part2-system-design/11-ml-systems/#recommendation-systems-netflixyoutube-scale","title":"Recommendation Systems (Netflix/YouTube scale)","text":"<p>Candidate Generation: 1M items \u2192 1K candidates in &lt;10ms - Collaborative filtering: User-item matrix factorization, 100M+ users - Content-based: Item embeddings, cosine similarity, real-time inference - Two-tower model: User tower + Item tower, dot product scoring</p> <p>Ranking Stage: 1K candidates \u2192 10 recommendations in &lt;50ms - Feature engineering: 1000+ features, real-time + batch - Model serving: TensorFlow Serving, 99.9% availability, &lt;20ms P95 - A/B testing: 1000+ experiments, statistical significance, guardrail metrics</p>"},{"location":"part2-system-design/11-ml-systems/#search-ranking-googlebing-scale","title":"Search Ranking (Google/Bing scale)","text":"<p>Query Understanding: 8.5B queries/day - Intent classification: Navigational/Informational/Transactional - Query expansion: Synonyms, typo correction, semantic matching - Personalization: Search history, location, device type</p> <p>Document Scoring: 100B+ documents indexed - TF-IDF baseline: Term frequency \u00d7 Inverse document frequency - Learning to Rank: LambdaMART, RankNet, pairwise loss functions - Neural ranking: BERT-based models, 768-dim embeddings</p>"},{"location":"part2-system-design/11-ml-systems/#real-time-ml-inference","title":"Real-time ML Inference","text":"<p>Feature Store Architecture: - Batch features: Daily ETL, historical aggregations, 24-hour freshness - Streaming features: Kafka + Flink, &lt;1 second freshness - Online features: Redis/DynamoDB, &lt;1ms lookup latency</p> <p>Model Serving Patterns: - Synchronous: REST API, &lt;100ms timeout, circuit breakers - Asynchronous: Message queues, batch prediction, cost optimization - Edge inference: Mobile/IoT, model quantization, &lt;10MB models</p>"},{"location":"part2-system-design/11-ml-systems/#training-infrastructure","title":"Training Infrastructure","text":"<p>Data Pipeline: 100TB+ training data - Feature extraction: Spark/Beam, distributed processing - Data validation: Schema drift detection, statistical tests - Versioning: DVC, MLflow, reproducible experiments</p> <p>Model Training: Multi-GPU/TPU clusters - Distributed training: Parameter servers, gradient synchronization - Hyperparameter tuning: Bayesian optimization, early stopping - Resource management: Kubernetes, auto-scaling, spot instances</p>"},{"location":"part2-system-design/11-ml-systems/#ml-monitoring-observability","title":"ML Monitoring &amp; Observability","text":"<p>Model Performance: - Accuracy drift: Statistical tests, confidence intervals - Latency monitoring: P50/P95/P99 inference time - Throughput: QPS, batch processing rates</p> <p>Data Quality: - Schema validation: Feature type/range checks - Distribution shift: KL divergence, population stability index - Missing values: Imputation strategies, default handling</p>"},{"location":"part2-system-design/tools/estimation_framework/","title":"System Estimation Framework","text":""},{"location":"part2-system-design/tools/estimation_framework/#step-1-scale-numbers-2-minutes","title":"Step 1: Scale Numbers (2 minutes)","text":"<pre><code>Users: DAU, MAU, growth rate\nTraffic: QPS read/write, seasonal patterns  \nData: Size per record, retention period\nGeography: Regions, latency requirements\n</code></pre>"},{"location":"part2-system-design/tools/estimation_framework/#step-2-sla-requirements-1-minute","title":"Step 2: SLA Requirements (1 minute)","text":"<pre><code>Latency: P50/P95/P99 targets\nAvailability: 99.9% vs 99.99% (cost difference)\nConsistency: Strong vs eventual vs session\nDurability: RPO (data loss tolerance)\n</code></pre>"},{"location":"part2-system-design/tools/estimation_framework/#step-3-resource-calculation-3-minutes","title":"Step 3: Resource Calculation (3 minutes)","text":"<pre><code>CPU: req/s \u00f7 (CPU_cores \u00d7 1000) &lt; 0.7 utilization\nMemory: working_set + cache + buffers + overhead\nStorage: data_size \u00d7 replication_factor \u00d7 growth_buffer\nNetwork: bandwidth \u00d7 peak_multiplier \u00d7 redundancy\n</code></pre>"},{"location":"part2-system-design/tools/estimation_framework/#step-4-cost-modeling-2-minutes","title":"Step 4: Cost Modeling (2 minutes)","text":"<pre><code>Infrastructure: Compute + storage + network + licenses\nOperational: Monitoring + backup + DR + support\nOpportunity: Engineering time + technical debt\n</code></pre>"},{"location":"part2-system-design/tools/estimation_framework/#step-5-bottleneck-analysis-2-minutes","title":"Step 5: Bottleneck Analysis (2 minutes)","text":"<pre><code>Identify limiting factor:\n- CPU bound: Horizontal scaling\n- Memory bound: Caching strategy  \n- I/O bound: Async processing\n- Network bound: CDN + compression\n</code></pre>"},{"location":"part2-system-design/tools/estimation_framework/#quick-reference-numbers","title":"Quick Reference Numbers","text":"<pre><code>Database: 1K QPS per core (OLTP), 10K QPS (read replica)\nCache: 100K ops/sec per Redis instance\nQueue: 10K msg/sec per Kafka partition\nCDN: 95% hit ratio typical, 99%+ for static assets\nNetwork: 1Gbps = 125MB/s, RTT adds 2\u00d7 latency minimum\n</code></pre>"},{"location":"part2-system-design/tools/quick_reference/","title":"Quick Reference \u2014 Numbers Every Engineer Should Know","text":""},{"location":"part2-system-design/tools/quick_reference/#latency-numbers-2024-edition","title":"Latency Numbers (2024 Edition)","text":"<pre><code>L1 cache reference:           0.5 ns\nBranch mispredict:            5 ns  \nL2 cache reference:           7 ns\nMutex lock/unlock:           100 ns\nMain memory reference:       100 ns\nCompress 1KB with Zippy:   10,000 ns = 10 \u03bcs\nSend 1KB over 1 Gbps:      10,000 ns = 10 \u03bcs\nRead 4KB randomly from SSD: 150,000 ns = 150 \u03bcs\nRead 1MB sequentially from memory: 250,000 ns = 250 \u03bcs\nRound trip within datacenter: 500,000 ns = 500 \u03bcs\nRead 1MB sequentially from SSD: 1,000,000 ns = 1 ms\nDisk seek: 10,000,000 ns = 10 ms\nRead 1MB sequentially from disk: 30,000,000 ns = 30 ms\nSend packet CA\u2192Netherlands\u2192CA: 150,000,000 ns = 150 ms\n</code></pre>"},{"location":"part2-system-design/tools/quick_reference/#throughput-benchmarks","title":"Throughput Benchmarks","text":"<pre><code>Redis: 100K ops/sec (single instance)\nPostgreSQL: 1K TPS (OLTP), 10K QPS (read replica)  \nMySQL: 1K TPS (OLTP), 15K QPS (read replica)\nKafka: 10K msg/sec per partition, 1M msg/sec per cluster\nElasticsearch: 10K docs/sec indexing, 100K queries/sec\nMongoDB: 5K writes/sec, 50K reads/sec (typical workload)\n</code></pre>"},{"location":"part2-system-design/tools/quick_reference/#storage-network","title":"Storage &amp; Network","text":"<pre><code>1 Gbps network = 125 MB/s theoretical, ~100 MB/s practical\n10 Gbps network = 1.25 GB/s theoretical, ~1 GB/s practical\nSSD: 500 MB/s sequential, 50K IOPS random\nNVMe SSD: 3 GB/s sequential, 500K IOPS random\nHDD: 100 MB/s sequential, 100 IOPS random\n</code></pre>"},{"location":"part2-system-design/tools/quick_reference/#cost-estimates-aws-us-east-1-2024","title":"Cost Estimates (AWS us-east-1, 2024)","text":"<pre><code>EC2 m5.large: $0.096/hour = $70/month\nRDS db.t3.medium: $0.068/hour = $50/month  \nS3 Standard: $0.023/GB/month\nEBS gp3: $0.08/GB/month\nData transfer out: $0.09/GB (first 10TB)\nCloudFront: $0.085/GB (first 10TB)\n</code></pre>"},{"location":"part2-system-design/tools/quick_reference/#rule-of-thumb-calculations","title":"Rule of Thumb Calculations","text":"<pre><code>Database connections = CPU cores \u00d7 2-4\nCache hit ratio target = 85%+ (90%+ for hot data)\nLoad balancer utilization = &lt;70% for burst capacity\nQueue depth alert = &gt;100 messages\nError budget (99.9%) = 43.8 minutes/month\nReplication lag target = &lt;1 second\n</code></pre>"},{"location":"part2-system-design/tools/tradeoff_decisions/","title":"Trade-off Decision Trees","text":""},{"location":"part2-system-design/tools/tradeoff_decisions/#consistency-model-decision","title":"Consistency Model Decision","text":"<pre><code>Strong Consistency Required?\n\u251c\u2500\u2500 Yes (Financial, Inventory)\n\u2502   \u251c\u2500\u2500 Single Region \u2192 ACID DB + Sync replication\n\u2502   \u2514\u2500\u2500 Multi Region \u2192 Consensus (Raft/Paxos) + Higher latency\n\u2514\u2500\u2500 No (Social, Analytics)\n    \u251c\u2500\u2500 Real-time Updates \u2192 Eventually consistent + Conflict resolution\n    \u2514\u2500\u2500 Batch Updates \u2192 Async replication + Reconciliation\n</code></pre>"},{"location":"part2-system-design/tools/tradeoff_decisions/#database-choice-decision","title":"Database Choice Decision","text":"<pre><code>Data Structure?\n\u251c\u2500\u2500 Relational (ACID, Complex queries)\n\u2502   \u251c\u2500\u2500 &lt;1TB \u2192 Single PostgreSQL/MySQL\n\u2502   \u2514\u2500\u2500 &gt;1TB \u2192 Sharded RDBMS or NewSQL\n\u251c\u2500\u2500 Document (Flexible schema)\n\u2502   \u251c\u2500\u2500 &lt;100GB \u2192 MongoDB single node\n\u2502   \u2514\u2500\u2500 &gt;100GB \u2192 MongoDB sharded or DynamoDB\n\u2514\u2500\u2500 Key-Value (Simple access patterns)\n    \u251c\u2500\u2500 In-memory \u2192 Redis/Memcached\n    \u2514\u2500\u2500 Persistent \u2192 DynamoDB/Cassandra\n</code></pre>"},{"location":"part2-system-design/tools/tradeoff_decisions/#caching-strategy-decision","title":"Caching Strategy Decision","text":"<pre><code>Access Pattern?\n\u251c\u2500\u2500 Read Heavy (90%+ reads)\n\u2502   \u251c\u2500\u2500 Static Data \u2192 CDN + Long TTL\n\u2502   \u2514\u2500\u2500 Dynamic Data \u2192 Application cache + Short TTL\n\u251c\u2500\u2500 Write Heavy (50%+ writes)\n\u2502   \u251c\u2500\u2500 Write-through \u2192 Consistency + Latency penalty\n\u2502   \u2514\u2500\u2500 Write-behind \u2192 Performance + Complexity\n\u2514\u2500\u2500 Mixed Workload\n    \u251c\u2500\u2500 Cache-aside \u2192 Manual management + Flexibility\n    \u2514\u2500\u2500 Read-through \u2192 Automatic + Cache warming needed\n</code></pre>"},{"location":"part2-system-design/tools/tradeoff_decisions/#scaling-strategy-decision","title":"Scaling Strategy Decision","text":"<pre><code>Current Bottleneck?\n\u251c\u2500\u2500 CPU Bound\n\u2502   \u251c\u2500\u2500 Stateless \u2192 Horizontal scaling (load balancer)\n\u2502   \u2514\u2500\u2500 Stateful \u2192 Vertical scaling or partitioning\n\u251c\u2500\u2500 Memory Bound  \n\u2502   \u251c\u2500\u2500 Cache Miss \u2192 Increase cache size or better eviction\n\u2502   \u2514\u2500\u2500 Memory Leak \u2192 Profiling + garbage collection tuning\n\u251c\u2500\u2500 I/O Bound\n\u2502   \u251c\u2500\u2500 Database \u2192 Read replicas or connection pooling\n\u2502   \u2514\u2500\u2500 Disk \u2192 SSD upgrade or async processing\n\u2514\u2500\u2500 Network Bound\n    \u251c\u2500\u2500 Bandwidth \u2192 CDN or compression\n    \u2514\u2500\u2500 Latency \u2192 Edge computing or protocol optimization\n</code></pre>"},{"location":"part2-system-design/tools/tradeoff_decisions/#microservices-vs-monolith","title":"Microservices vs Monolith","text":"<pre><code>Team Size &amp; Complexity?\n\u251c\u2500\u2500 &lt;8 people, &lt;10 services \u2192 Modular monolith\n\u251c\u2500\u2500 8-20 people, 10-50 services \u2192 Microservices + Service mesh\n\u2514\u2500\u2500 &gt;20 people, &gt;50 services \u2192 Domain-driven design + Platform team\n\nDeployment Frequency?\n\u251c\u2500\u2500 Weekly/Monthly \u2192 Monolith (simpler deployment)\n\u2514\u2500\u2500 Daily/Hourly \u2192 Microservices (independent deployment)\n\nTechnology Diversity?\n\u251c\u2500\u2500 Single stack \u2192 Monolith (shared libraries)\n\u2514\u2500\u2500 Polyglot \u2192 Microservices (best tool per service)\n</code></pre>"},{"location":"part3-execution/01-8-week-schedule/","title":"8-Week Schedule (Daily)","text":"<p>90 minutes/day, 6 days/week, 1 rest day. Each day: Coding (45m) + System Design (30m) + Debrief (15m).</p>"},{"location":"part3-execution/01-8-week-schedule/#week-1-baseline-foundations","title":"Week 1 \u2014 Baseline &amp; Foundations","text":"<ul> <li>Coding: Hash/Two Sum, Sliding Window basics; focus on traces and complexity fluency.</li> <li>System Design: latency/throughput math, Little's Law drills, availability equations.</li> <li>Debrief: start mistake log; record timing per problem.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-2-data-structures-caching","title":"Week 2 \u2014 Data Structures &amp; Caching","text":"<ul> <li>Coding: BFS/graphs, Intervals. Time-box to 25m per medium.</li> <li>System Design: caching/LB/queues; compute \u03b7, \u03c1; stampede mitigations.</li> <li>Mock 1 (end of week): 35m system design on URL shortener.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-3-dptopo-storage","title":"Week 3 \u2014 DP/Topo &amp; Storage","text":"<ul> <li>Coding: DP (rolling), Topological sort; add 1 hard problem mid-week.</li> <li>System Design: sharding/replication/quorums; pick N/R/W configs and narrate tradeoffs.</li> <li>Debrief themes: edge cases missed, communication gaps.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-4-observability-reliability","title":"Week 4 \u2014 Observability &amp; Reliability","text":"<ul> <li>Coding: Heaps/greedy; mixed review set across archetypes.</li> <li>System Design: observability, reliability, security; design SLOs and alerting.</li> <li>Mock 2: messaging system; emphasize failure modes and backpressure.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-5-cloud-mapping-costs","title":"Week 5 \u2014 Cloud Mapping &amp; Costs","text":"<ul> <li>Coding: Two mixed mediums per day; enforce 10m for testcases before coding.</li> <li>System Design: cloud service mapping, cost/latency tiers, egress math.</li> <li>Deliverable: personal playbook of \u201cdefault stacks\u201d for common problems.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-6-case-studies-incident-thinking","title":"Week 6 \u2014 Case Studies &amp; Incident Thinking","text":"<ul> <li>Coding: alternate easy+hard sets to practice pacing.</li> <li>System Design: walk through bit.ly, WhatsApp, payments; calculate QPS/storage/live cache sizes.</li> <li>Mock 3: payments or booking; drive idempotency, consistency choices.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-7-full-length-reps","title":"Week 7 \u2014 Full-Length Reps","text":"<ul> <li>Coding: 1 easy warmup + 1 medium/hard timed daily.</li> <li>System Design: 45m full mocks with follow-up questions; rotate interviewers if possible.</li> <li>Debrief: refine intro template and \u201cclosing recap\u201d script.</li> </ul>"},{"location":"part3-execution/01-8-week-schedule/#week-8-polish-recovery","title":"Week 8 \u2014 Polish &amp; Recovery","text":"<ul> <li>Coding: light review; focus on weak archetypes only.</li> <li>System Design: 2-3 mocks; add a war-story snippet to each design.</li> <li>Meta: sleep, pacing, talk track; update cheat sheets and mistake log; taper intensity before interviews.</li> </ul>"},{"location":"part3-execution/02-mock-rubrics/","title":"Mock Rubrics","text":""},{"location":"part3-execution/02-mock-rubrics/#coding-score-14","title":"Coding (score 1\u20134)","text":"<ul> <li>Understanding: Restates the problem/constraints, asks for clarifications, identifies edge cases.</li> <li>Approach: Chooses an appropriate pattern, explains why it fits, outlines steps before coding.</li> <li>Correctness: Covers core logic and edge cases; tests with sample and corner inputs.</li> <li>Complexity: States time/space and tradeoffs; can justify choices (e.g., hash vs sort).</li> <li>Communication: Narrates intent while coding; concise, structured, keeps interviewer in the loop.</li> </ul>"},{"location":"part3-execution/02-mock-rubrics/#system-design-score-14","title":"System Design (score 1\u20134)","text":"<ul> <li>Requirements: Captures functional/non-functional needs, scale/SLA targets, success metrics.</li> <li>Estimation: Back-of-envelope QPS/storage/hotset numbers; identifies bottlenecks.</li> <li>Architecture: Clear high-level diagram; correct placement of caches/LB/queues/data stores.</li> <li>Scalability/Reliability: Sharding/replication/quorum choices; failover, backpressure, degradation modes.</li> <li>Ops/Cost: Observability plan, deployment/rollout, cost drivers/optimizations.</li> <li>Communication: Structured flow (clarify \u2192 estimate \u2192 design \u2192 deep dive \u2192 risks); trades-offs articulated.</li> </ul>"},{"location":"part3-execution/03-mistake-log-template/","title":"Mistake Log Template","text":"<p>Date: Problem / System: Archetype / Pattern: Mistake (1\u20132 lines): Root cause (syntax / logic / edge / pressure / math): Fix (rule / checklist item): Lesson (one sentence): Infra analogy:</p>"},{"location":"part3-execution/04-cheatsheets/","title":"Cheatsheets","text":""},{"location":"part3-execution/04-cheatsheets/#coding","title":"Coding","text":"<ul> <li>Hashing: map complement; O(n).</li> <li>Sliding window: grow/shrink; O(n).</li> <li>BFS: queue wavefront; O(V+E).</li> <li>Intervals: sort+merge; O(n log n).</li> <li>DP: rolling recurrence; O(n)/O(1).</li> <li>Topo: indegree queue; cycle if processed&lt;V.</li> <li>Heap/Greedy: earliest finish min-heap; O(n log n).</li> </ul>"},{"location":"part3-execution/04-cheatsheets/#system-design","title":"System Design","text":"<ul> <li>Clarify \u2192 Estimate \u2192 Sketch \u2192 Deep-dive \u2192 Evolve \u2192 SLO/Cost.</li> <li>Key equations: E[L]=\u03b7L1+(1-\u03b7)L2; \u03c1=\u03bb/\u03bc; A=1-p^N; quorum R+W&gt;N.</li> <li>Cloud mapping table included.</li> </ul>"},{"location":"part3-execution/05-practice-set/","title":"Canonical Practice Set","text":"<p>Hashing: Two Sum; Subarray Sum = K; 3Sum. Sliding Window: Longest Substring; Permutation in String; Min Window Substring (bonus). BFS/Graphs: Level Order; Clone Graph; Number of Islands; Shortest Path (grid). Intervals: Merge Intervals; Insert Interval; Meeting Rooms I. DP: Climb Stairs; House Robber; LIS. Topo: Course Schedule I/II; Alien Dictionary (bonus). Heap/Greedy: Meeting Rooms II; Top K Frequent; Task Scheduler.</p> <p>Time-box: Easy 15m, Medium 25m. Always write a trace and complexity.</p>"},{"location":"part3-execution/06-faang-specific-prep/","title":"FAANG-Specific Interview Prep","text":""},{"location":"part3-execution/06-faang-specific-prep/#company-specific-focus-areas","title":"Company-Specific Focus Areas","text":""},{"location":"part3-execution/06-faang-specific-prep/#metafacebook","title":"Meta/Facebook","text":"<p>Coding: Graph algorithms, BFS/DFS variations, dynamic programming System Design: Social networks, real-time systems, distributed consensus Behavioral: \"Move Fast and Break Things\" \u2192 impact, ownership, collaboration Bar: L5 (Senior) = 5+ years, L6 (Staff) = 8+ years, strong system design</p>"},{"location":"part3-execution/06-faang-specific-prep/#google","title":"Google","text":"<p>Coding: Algorithm optimization, complexity analysis, clean code System Design: Scalability, reliability, distributed systems fundamentals Behavioral: \"Googleyness\" \u2192 intellectual humility, learning mindset Bar: L5 (Senior) = 5+ years, L6 (Staff) = 7+ years, exceptional problem-solving</p>"},{"location":"part3-execution/06-faang-specific-prep/#amazon","title":"Amazon","text":"<p>Coding: Object-oriented design, scalability considerations System Design: Cost optimization, operational excellence, customer obsession Behavioral: 14 Leadership Principles, STAR method, customer impact stories Bar: L6 (Senior) = 4+ years, L7 (Principal) = 8+ years, business impact focus</p>"},{"location":"part3-execution/06-faang-specific-prep/#apple","title":"Apple","text":"<p>Coding: Memory management, performance optimization, attention to detail System Design: Privacy-first design, hardware-software integration Behavioral: Innovation, quality, user experience focus Bar: ICT4 (Senior) = 5+ years, ICT5 (Staff) = 8+ years, product excellence</p>"},{"location":"part3-execution/06-faang-specific-prep/#netflix","title":"Netflix","text":"<p>Coding: Microservices patterns, fault tolerance, performance System Design: Chaos engineering, global scale, cost efficiency Behavioral: Culture of freedom and responsibility, high performance Bar: Senior = 5+ years, Staff = 8+ years, operational excellence</p>"},{"location":"part3-execution/06-faang-specific-prep/#interview-timeline-strategy","title":"Interview Timeline &amp; Strategy","text":""},{"location":"part3-execution/06-faang-specific-prep/#weeks-1-2-foundation-building","title":"Weeks 1-2: Foundation Building","text":"<ul> <li>Daily: 2 coding problems (1 easy, 1 medium)</li> <li>System Design: Complete foundations + caching modules</li> <li>Behavioral: Draft STAR stories for each company's values</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#weeks-3-4-pattern-mastery","title":"Weeks 3-4: Pattern Mastery","text":"<ul> <li>Daily: 2 medium problems + 1 hard problem weekly</li> <li>System Design: Case studies + failure engineering</li> <li>Mock Interviews: 1 coding + 1 system design per week</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#weeks-5-6-company-specific-deep-dive","title":"Weeks 5-6: Company-Specific Deep Dive","text":"<ul> <li>Target Company Focus: Study their engineering blog, architecture</li> <li>System Design: Practice their actual interview questions</li> <li>Behavioral: Refine stories for their specific culture</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#weeks-7-8-interview-simulation","title":"Weeks 7-8: Interview Simulation","text":"<ul> <li>Daily: Timed practice (45min coding, 60min system design)</li> <li>Mock Interviews: 3 per week with different interviewers</li> <li>Final Prep: Review mistake log, practice presentation skills</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#success-metrics-by-level","title":"Success Metrics by Level","text":""},{"location":"part3-execution/06-faang-specific-prep/#l5senior-5-7-years-experience","title":"L5/Senior (5-7 years experience)","text":"<ul> <li>Coding: Solve medium problems in &lt;25 minutes, hard in &lt;40 minutes</li> <li>System Design: Design systems for 10M+ users with proper trade-offs</li> <li>Behavioral: 3-4 strong STAR stories demonstrating leadership</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#l6staff-7-10-years-experience","title":"L6/Staff (7-10 years experience)","text":"<ul> <li>Coding: Optimize solutions, discuss multiple approaches, mentor others</li> <li>System Design: Handle ambiguity, drive technical decisions, cost analysis</li> <li>Behavioral: Cross-team impact, technical strategy, conflict resolution</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#l7principal-10-years-experience","title":"L7/Principal (10+ years experience)","text":"<ul> <li>Coding: Architectural thinking, framework design, performance analysis</li> <li>System Design: Multi-year technical vision, org-level impact</li> <li>Behavioral: Technical leadership, industry influence, strategic thinking</li> </ul>"},{"location":"part3-execution/06-faang-specific-prep/#red-flags-to-avoid","title":"Red Flags to Avoid","text":"<ul> <li>Coding: Brute force without optimization, poor variable naming, no testing</li> <li>System Design: Over-engineering, ignoring constraints, no monitoring</li> <li>Behavioral: Negative stories, taking all credit, no growth mindset</li> <li>General: Late arrival, poor communication, not asking clarifying questions</li> </ul>"}]}